This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
backend/
  README.md
data/
  README.md
docker/
  README.md
docs/
  README.md
frontend/
  README.md
ml-service/
  data/
     test_with_generated_data.py
    advanced_generator.py
    generate_test_data.py
  models/
    behavioral_twin.py
    fraud_detector.py
  tests/
    test_basic.py
  utils/
    explainability.py
    model_persistence.py
    monitoring.py
  .gitignore
  advanced_sample.csv
  app.py
  dashboard.html
  mlservice_test.py
  network_test.py
  quick_test.py
  README.md
  requirements.txt
  test_all_features.py
  test_fraudguard.py
.gitignore
README.md
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="ml-service/network_test.py">
import requests
import random
import time
from datetime import datetime

BASE_URL = 'http://localhost:8000'

def test_network_endpoints():
    """Test the network/cycles endpoint"""
    print("üîó Testing Network Visualization Endpoints")
    print("=" * 50)
    
    try:
        # Test cycles endpoint
        response = requests.get(f'{BASE_URL}/monitoring/cycles')
        if response.status_code == 200:
            data = response.json()
            print("‚úÖ Cycles endpoint working")
            print(f"   Nodes: {data['statistics']['total_nodes']}")
            print(f"   Edges: {data['statistics']['total_edges']}")
            print(f"   Cycles Detected: {data['statistics']['cycles_detected']}")
            print(f"   Fraud Rings: {data['analysis_summary']['fraud_rings_detected']}")
        else:
            print(f"‚ùå Cycles endpoint failed: {response.status_code}")
    
    except Exception as e:
        print(f"‚ùå Network test failed: {e}")

def generate_network_activity():
    """Generate activity to populate network visualization"""
    print("üåê Generating Network Activity...")
    
    # Train multiple users first
    users = ['NETWORK_USER_A', 'NETWORK_USER_B', 'NETWORK_USER_C', 'SUSPICIOUS_USER_X']
    
    for user in users:
        transactions = []
        for i in range(15):
            # Create different spending patterns for each user
            if user == 'SUSPICIOUS_USER_X':
                amount = random.uniform(1000, 5000)  # Suspicious amounts
                category = random.choice(['electronics', 'jewelry', 'travel'])
                hour = random.choice([1, 2, 3, 4])  # Suspicious times
            else:
                amount = random.uniform(20, 300)     # Normal amounts
                category = random.choice(['grocery', 'gas', 'restaurant', 'retail'])
                hour = random.randint(8, 22)        # Normal times
            
            transactions.append({
                'user_id': user,
                'amount': amount,
                'merchant_category': category,
                'hour': hour,
                'day_of_week': random.randint(0, 6)
            })
        
        # Train user
        train_data = {'user_id': user, 'transactions': transactions}
        response = requests.post(f'{BASE_URL}/train-user', json=train_data)
        
        if response.status_code == 200:
            print(f"‚úÖ Trained {user}")
        else:
            print(f"‚ùå Failed to train {user}")
        
        time.sleep(0.5)
    
    # Generate transactions between users to create network relationships
    print("üîÑ Creating Network Relationships...")
    
    network_transactions = [
        # Normal transaction chain
        {'user_id': 'NETWORK_USER_A', 'amount': 150, 'merchant_category': 'transfer', 'hour': 14, 'day_of_week': 2},
        {'user_id': 'NETWORK_USER_B', 'amount': 200, 'merchant_category': 'restaurant', 'hour': 19, 'day_of_week': 3},
        {'user_id': 'NETWORK_USER_C', 'amount': 100, 'merchant_category': 'grocery', 'hour': 18, 'day_of_week': 4},
        
        # Suspicious cycle
        {'user_id': 'SUSPICIOUS_USER_X', 'amount': 3000, 'merchant_category': 'electronics', 'hour': 2, 'day_of_week': 6},
        {'user_id': 'NETWORK_USER_A', 'amount': 2800, 'merchant_category': 'jewelry', 'hour': 3, 'day_of_week': 0},
        {'user_id': 'NETWORK_USER_B', 'amount': 3500, 'merchant_category': 'travel', 'hour': 1, 'day_of_week': 5},
        {'user_id': 'SUSPICIOUS_USER_X', 'amount': 5000, 'merchant_category': 'cash_advance', 'hour': 4, 'day_of_week': 6},
    ]
    
    fraud_detected = 0
    for transaction in network_transactions:
        response = requests.post(f'{BASE_URL}/detect-fraud', json=transaction)
        if response.status_code == 200:
            result = response.json()
            if result['is_suspicious']:
                fraud_detected += 1
                print(f"üö® Fraud detected: {transaction['user_id']} - {result['risk_level']}")
            else:
                print(f"‚úÖ Normal: {transaction['user_id']} - {result['risk_level']}")
        time.sleep(1)
    
    print(f"\nüìä Network Activity Generated:")
    print(f"   Users Trained: {len(users)}")
    print(f"   Transactions Processed: {len(network_transactions)}")
    print(f"   Fraud Detected: {fraud_detected}")
    print(f"üåê Check network visualization at: http://localhost:8000/dashboard")

if __name__ == '__main__':
    test_network_endpoints()
    print()
    generate_network_activity()
</file>

<file path="backend/README.md">
# Backend Service - Spring Boot API
</file>

<file path="data/README.md">
# Data - Datasets and Schemas
</file>

<file path="docker/README.md">
# Docker - Container Configurations
</file>

<file path="docs/README.md">
# Documentation
</file>

<file path="frontend/README.md">
# Frontend - React Dashboard
</file>

<file path="ml-service/data/ test_with_generated_data.py">
import requests
import pandas as pd
from data.advanced_generator import AdvancedDataGenerator

def test_ml_service_with_realistic_data():
    """Test ML service with realistic generated data"""
    base_url = "http://localhost:8000"
    generator = AdvancedDataGenerator()
    
    # 1. Check service health
    response = requests.get(f"{base_url}/")
    print("üõ°Ô∏è FraudGuard ML Service Status:", response.json()['message'])
    
    # 2. Generate training data for a professional user
    user_id = "USER_PROFESSIONAL_TEST"
    training_transactions = generator.generate_user_transactions(user_id, "professional", 25)
    
    # 3. Train the user model
    training_data = {
        "user_id": user_id,
        "transactions": training_transactions
    }
    
    print(f"\nüß† Training model for {user_id}...")
    response = requests.post(f"{base_url}/train-user", json=training_data)
    
    if response.status_code == 200:
        result = response.json()
        profile = result['profile']
        print(f"   ‚úÖ Training successful!")
        print(f"   üìä Profile: {profile['total_transactions']} transactions, avg=${profile['avg_amount']:.2f}")
    else:
        print(f"   ‚ùå Training failed: {response.text}")
        return
    
    # 4. Test normal transaction detection
    normal_txn = {
        "user_id": user_id,
        "amount": 180.0,  # Close to professional average
        "merchant_category": "restaurant",  # Common for professionals
        "hour": 19,  # Evening
        "day_of_week": 3,  # Thursday
        "location": "normal_area"
    }
    
    print(f"\n‚úÖ Testing normal transaction...")
    response = requests.post(f"{base_url}/detect-fraud", json=normal_txn)
    result = response.json()
    print(f"   Result: {result['risk_level']} (score: {result['anomaly_score']:.3f})")
    
    # 5. Test suspicious transaction detection
    suspicious_txn = {
        "user_id": user_id,
        "amount": 3000.0,  # Very high for professional
        "merchant_category": "jewelry",  # High-risk category
        "hour": 2,  # 2 AM
        "day_of_week": 6,  # Sunday
        "location": "suspicious_area"
    }
    
    print(f"\nüö® Testing suspicious transaction...")
    response = requests.post(f"{base_url}/detect-fraud", json=suspicious_txn)
    result = response.json()
    print(f"   Result: {result['risk_level']} (score: {result['anomaly_score']:.3f})")
    print(f"   Explanation: {result['explanation'][0][:60]}...")
    
    print(f"\nüéâ Realistic data testing completed!")

if __name__ == "__main__":
    test_ml_service_with_realistic_data()
</file>

<file path="ml-service/data/advanced_generator.py">
from faker import Faker
import random
import pandas as pd
import numpy as np
from datetime import datetime

fake = Faker()

class AdvancedDataGenerator:
    def __init__(self):
        self.personas = {
            'student': {'base_amount': 50, 'categories': ['grocery', 'restaurant', 'gas'], 'fraud_rate': 0.03},
            'professional': {'base_amount': 200, 'categories': ['restaurant', 'retail', 'gas', 'grocery'], 'fraud_rate': 0.05},
            'family': {'base_amount': 150, 'categories': ['grocery', 'pharmacy', 'retail'], 'fraud_rate': 0.07},
            'high_roller': {'base_amount': 500, 'categories': ['restaurant', 'travel', 'luxury'], 'fraud_rate': 0.15},
        }

    def generate_user_transactions(self, user_id, persona='professional', n=30):
        config = self.personas.get(persona, self.personas['professional'])
        base = config['base_amount']
        cats = config['categories']
        fraud_rate = config['fraud_rate']

        transactions = []
        frauds = 0
        for i in range(n):
            is_fraud = (random.random() < fraud_rate)
            if is_fraud:
                amount = base * random.uniform(5, 15)
                cat = random.choice(['electronics', 'jewelry', 'travel', 'cash_advance'])
                hour = random.choice([1, 2, 3, 4, 23])
                day = random.choice([5, 6])
                location = 'suspicious_area'
                frauds += 1
            else:
                amount = max(5, random.gauss(base, base*0.3))
                cat = random.choice(cats)
                hour = random.choice(range(7, 22))
                day = random.choice(range(0, 5))
                location = 'normal_area'
            transaction = {
                'user_id': user_id,
                'amount': round(amount, 2),
                'merchant_category': cat,
                'hour': hour,
                'day': day,
                'location': location,
                'is_fraud': is_fraud,
                'timestamp': datetime.now().isoformat()
            }
            transactions.append(transaction)
        print(f"Generated {n} transactions for {user_id} ({frauds} fraudulent)")
        return transactions

if __name__ == '__main__':
    gen = AdvancedDataGenerator()
    user_txns = gen.generate_user_transactions('USER_001', 'professional', 30)
    df = pd.DataFrame(user_txns)
    df.to_csv('advanced_sample.csv', index=False)
    print('Sample data saved to advanced_sample.csv')
</file>

<file path="ml-service/data/generate_test_data.py">
from data.advanced_generator import AdvancedDataGenerator
import pandas as pd

def create_test_dataset():
    """Generate comprehensive test dataset"""
    generator = AdvancedDataGenerator()
    
    all_transactions = []
    
    # Generate users with different personas
    test_users = [
        ("USER_STUDENT_001", "student", 25),
        ("USER_STUDENT_002", "student", 20),
        ("USER_PROFESSIONAL_001", "professional", 35),
        ("USER_PROFESSIONAL_002", "professional", 30),
        ("USER_FAMILY_001", "family", 40),
        ("USER_FAMILY_002", "family", 35),
        ("USER_HIGHROLLER_001", "high_roller", 25),
    ]
    
    for user_id, persona, num_txns in test_users:
        print(f"\nüé≠ Generating data for {user_id} ({persona})...")
        user_transactions = generator.generate_user_transactions(user_id, persona, num_txns)
        all_transactions.extend(user_transactions)
    
    # Save comprehensive dataset
    df = pd.DataFrame(all_transactions)
    df.to_csv('comprehensive_test_data.csv', index=False)
    
    # Print summary
    total_fraud = df['is_fraud'].sum()
    fraud_rate = total_fraud / len(df) * 100
    
    print(f"\nüìä Dataset Summary:")
    print(f"   Total Users: {len(test_users)}")
    print(f"   Total Transactions: {len(df)}")
    print(f"   Fraudulent Transactions: {total_fraud}")
    print(f"   Fraud Rate: {fraud_rate:.1f}%")
    print(f"   Saved to: comprehensive_test_data.csv")

if __name__ == "__main__":
    create_test_dataset()
</file>

<file path="ml-service/models/behavioral_twin.py">
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from typing import List, Dict

class BehavioralTwin:
    def __init__(self):
        self.user_profiles = {}
        self.models = {}
        self.scalers = {}

    def create_profile(self, user_id: str, transactions: List[Dict]):
        df = pd.DataFrame(transactions)

        # Calculate basic user stats
        profile = {
            'user_id': user_id,
            'transaction_count': len(transactions),
            'avg_amount': df['amount'].mean(),
            'std_amount': df['amount'].std(),
            'median_amount': df['amount'].median(),
            'max_amount': df['amount'].max(),
            'common_categories': df['merchant_category'].value_counts().head(5).to_dict(),
            'active_hours': df['hour'].value_counts().head(8).index.tolist(),
            'active_days': df['day_of_week'].value_counts().index.tolist(),
        }

        features = self._extract_features(df)
        scaler = StandardScaler()
        scaled_features = scaler.fit_transform(features)

        model = IsolationForest(contamination=0.1, n_estimators=100, random_state=42)
        model.fit(scaled_features)

        self.user_profiles[user_id] = profile
        self.models[user_id] = model
        self.scalers[user_id] = scaler

        return profile

    def _extract_features(self, df: pd.DataFrame) -> np.ndarray:
        features = []
        for _, row in df.iterrows():
            features.append([
                row['amount'],
                row['hour'],
                row['day_of_week'],
                hash(row['merchant_category']) % 10000
            ])
        return np.array(features)

    def detect_anomaly(self, user_id: str, transaction: Dict) -> Dict:
        if user_id not in self.models:
            return {
                'anomaly_score': 0,
                'is_anomaly': False,
                'explanation': ['User not trained'],
            }

        model = self.models[user_id]
        scaler = self.scalers[user_id]
        profile = self.user_profiles[user_id]

        features = self._extract_single_feature(transaction)
        scaled_features = scaler.transform([features])

        score = model.decision_function(scaled_features)[0]
        normalized_score = max(0, min(1, (0.5 - score)))

        explanation = []

        if transaction['amount'] > profile['avg_amount'] + 2 * profile['std_amount']:
            explanation.append('Amount unusually high')
        if transaction['hour'] not in profile['active_hours'][:5]:
            explanation.append('Transaction time unusual')
        if transaction['merchant_category'] not in profile['common_categories']:
            explanation.append('Merchant category unusual')

        return {
            'anomaly_score': normalized_score,
            'is_anomaly': normalized_score > 0.6,
            'explanation': explanation
        }

    def _extract_single_feature(self, transaction: Dict) -> List[float]:
        return [
            transaction['amount'],
            transaction['hour'],
            transaction['day_of_week'],
            hash(transaction['merchant_category']) % 10000
        ]
</file>

<file path="ml-service/models/fraud_detector.py">
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import joblib
import logging
from typing import Dict, List, Tuple
from datetime import datetime

logger = logging.getLogger("fraudguard_ml")

class EnsembleFraudDetector:
    """Advanced ensemble fraud detection combining multiple ML models and business rules"""
    
    def __init__(self):
        self.models = {
            'isolation_forest': None,  # Already exists
            'random_forest': RandomForestClassifier(
                n_estimators=200, 
                max_depth=10, 
                random_state=42,
                class_weight='balanced'
            ),
            'gradient_boost': GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            ),
            'neural_network': MLPClassifier(
                hidden_layer_sizes=(100, 50),
                max_iter=1000,
                random_state=42,
                early_stopping=True
            ),
            'logistic_regression': LogisticRegression(
                random_state=42,
                class_weight='balanced',
                max_iter=1000
            )
        }
        
        self.scalers = {}
        self.model_weights = {
            'isolation_forest': 0.3,
            'random_forest': 0.25,
            'gradient_boost': 0.2,
            'neural_network': 0.15,
            'logistic_regression': 0.1
        }
        
        self.business_rules_weight = 0.2
        self.ensemble_threshold = 0.6
        
    def prepare_training_data(self, transactions: List[Dict], labels: List[int] = None) -> Tuple[np.ndarray, np.ndarray]:
        """Prepare data for supervised learning with synthetic fraud labels"""
        df = pd.DataFrame(transactions)
        
        # Extract features
        features = []
        fraud_labels = []
        
        for i, (_, row) in enumerate(df.iterrows()):
            feature_vector = [
                row['amount'],
                row['hour'],
                row['day_of_week'],
                hash(row['merchant_category']) % 1000,
                1 if row['day_of_week'] in [5, 6] else 0,  # Weekend
                1 if row['hour'] in [22, 23, 0, 1, 2, 3, 4, 5] else 0,  # Night
                len(str(row['merchant_category'])),  # Category length
                1 if row['amount'] > 1000 else 0,  # High amount flag
            ]
            features.append(feature_vector)
            
            # Generate synthetic fraud labels based on suspicious patterns
            if labels and i < len(labels):
                fraud_labels.append(labels[i])
            else:
                # Synthetic labeling based on known fraud indicators
                is_fraud = (
                    row['amount'] > 2000 and 
                    row['hour'] in [0, 1, 2, 3, 4] and 
                    row['merchant_category'] in ['electronics', 'jewelry', 'travel']
                )
                fraud_labels.append(1 if is_fraud else 0)
        
        return np.array(features), np.array(fraud_labels)
    
    def train_ensemble(self, user_id: str, transactions: List[Dict], labels: List[int] = None):
        """Train all models in the ensemble"""
        logger.info(f"ü§ñ Training ensemble models for {user_id}")
        
        X, y = self.prepare_training_data(transactions, labels)
        
        # Scale features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers[user_id] = scaler
        
        trained_models = {}
        
        # Train supervised models (skip isolation forest as it's already trained)
        for name, model in self.models.items():
            if name == 'isolation_forest':
                continue
                
            try:
                logger.info(f"  Training {name}...")
                model.fit(X_scaled, y)
                
                # Cross-validation score
                cv_score = cross_val_score(model, X_scaled, y, cv=3, scoring='f1').mean()
                logger.info(f"  {name} CV F1-score: {cv_score:.3f}")
                
                trained_models[name] = model
                
            except Exception as e:
                logger.warning(f"  Failed to train {name}: {e}")
        
        self.models.update(trained_models)
        
        # Calculate fraud rate for user
        fraud_rate = np.mean(y)
        logger.info(f"‚úÖ Ensemble training completed. Fraud rate: {fraud_rate:.1%}")
        
        return {
            'models_trained': list(trained_models.keys()),
            'fraud_rate': fraud_rate,
            'total_transactions': len(transactions)
        }
    
    def predict_ensemble(self, user_id: str, transaction: Dict, isolation_score: float = None) -> Dict:
        """Make ensemble prediction combining all models"""
        
        # Extract features
        features = [
            transaction['amount'],
            transaction['hour'],
            transaction['day_of_week'],
            hash(transaction['merchant_category']) % 1000,
            1 if transaction['day_of_week'] in [5, 6] else 0,
            1 if transaction['hour'] in [22, 23, 0, 1, 2, 3, 4, 5] else 0,
            len(str(transaction['merchant_category'])),
            1 if transaction['amount'] > 1000 else 0,
        ]
        
        # Scale features
        if user_id in self.scalers:
            features_scaled = self.scalers[user_id].transform([features])
        else:
            features_scaled = np.array([features])
        
        model_predictions = {}
        model_probabilities = {}
        
        # Get predictions from all models
        for name, model in self.models.items():
            if name == 'isolation_forest':
                if isolation_score is not None:
                    # Use provided isolation forest score
                    model_predictions[name] = 1 if isolation_score > 0.6 else 0
                    model_probabilities[name] = isolation_score
                continue
            
            try:
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba(features_scaled)[0]
                    fraud_proba = proba[1] if len(proba) > 1 else proba[0]
                    model_probabilities[name] = fraud_proba
                    model_predictions[name] = 1 if fraud_proba > 0.5 else 0
                else:
                    pred = model.predict(features_scaled)[0]
                    model_predictions[name] = pred
                    model_probabilities[name] = float(pred)
                    
            except Exception as e:
                logger.warning(f"Prediction failed for {name}: {e}")
                model_predictions[name] = 0
                model_probabilities[name] = 0.0
        
        # Calculate weighted ensemble score
        ensemble_score = 0.0
        total_weight = 0.0
        
        for name, weight in self.model_weights.items():
            if name in model_probabilities:
                ensemble_score += weight * model_probabilities[name]
                total_weight += weight
        
        # Normalize
        if total_weight > 0:
            ensemble_score /= total_weight
        
        # Business rules adjustment
        business_score = self._apply_advanced_business_rules(transaction)
        final_score = (ensemble_score * 0.8) + (business_score * 0.2)
        
        # Determine final prediction
        is_fraud = final_score > self.ensemble_threshold
        
        # Risk level
        if final_score > 0.9:
            risk_level = "CRITICAL"
        elif final_score > 0.7:
            risk_level = "HIGH"
        elif final_score > 0.5:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"
        
        return {
            'ensemble_score': final_score,
            'is_fraud': is_fraud,
            'risk_level': risk_level,
            'model_predictions': model_predictions,
            'model_probabilities': model_probabilities,
            'business_rules_score': business_score,
            'confidence': abs(final_score - 0.5) * 2
        }
    
    def _apply_advanced_business_rules(self, transaction: Dict) -> float:
        """Apply comprehensive business rules"""
        score = 0.0
        
        amount = transaction['amount']
        hour = transaction['hour']
        day = transaction['day_of_week']
        category = transaction['merchant_category']
        
        # Amount-based rules
        if amount > 10000:
            score += 0.4
        elif amount > 5000:
            score += 0.2
        elif amount > 2000:
            score += 0.1
        
        # Time-based rules
        if hour in [0, 1, 2, 3, 4, 5]:  # Late night
            score += 0.3
        elif hour in [22, 23]:  # Very late evening
            score += 0.1
        
        # Category-based rules
        high_risk_categories = ['electronics', 'jewelry', 'travel', 'cash_advance', 'gambling']
        medium_risk_categories = ['online', 'retail', 'entertainment']
        
        if category in high_risk_categories:
            score += 0.3
        elif category in medium_risk_categories:
            score += 0.1
        
        # Weekend late night combination
        if day in [5, 6] and hour in [22, 23, 0, 1, 2]:
            score += 0.2
        
        # Round amounts (potential testing)
        if amount % 100 == 0 and amount > 500:
            score += 0.1
        
        return min(1.0, score)
    
    def get_ensemble_explanation(self, prediction_result: Dict, transaction: Dict) -> List[str]:
        """Generate detailed ensemble explanations"""
        explanations = []
        
        # Model agreement analysis
        predictions = prediction_result['model_predictions']
        fraud_votes = sum(predictions.values())
        total_votes = len(predictions)
        
        if fraud_votes > total_votes * 0.7:
            explanations.append(f"üö® Strong consensus: {fraud_votes}/{total_votes} models flagged as fraud")
        elif fraud_votes > total_votes * 0.5:
            explanations.append(f"‚ö†Ô∏è Moderate consensus: {fraud_votes}/{total_votes} models flagged as fraud")
        else:
            explanations.append(f"‚úÖ Low risk: Only {fraud_votes}/{total_votes} models flagged as fraud")
        
        # Individual model insights
        probabilities = prediction_result['model_probabilities']
        top_model = max(probabilities.keys(), key=lambda x: probabilities[x])
        explanations.append(f"üéØ Strongest signal from: {top_model} ({probabilities[top_model]:.3f})")
        
        # Business rules contribution
        business_score = prediction_result['business_rules_score']
        if business_score > 0.5:
            explanations.append(f"üìã Business rules strongly support fraud ({business_score:.3f})")
        elif business_score > 0.2:
            explanations.append(f"üìã Business rules moderately support fraud ({business_score:.3f})")
        
        return explanations
</file>

<file path="ml-service/tests/test_basic.py">
import requests

BASE_URL = "http://localhost:8000"

def test_health_check():
    resp = requests.get(f"{BASE_URL}/")
    assert resp.status_code == 200
    print("‚úÖ Health check passed")

def test_docs_available():
    resp = requests.get(f"{BASE_URL}/docs")
    assert resp.status_code == 200
    print("‚úÖ Swagger docs available")

def test_training_endpoint():
    user_id = "TEST_USER"
    transactions = [
        {
            "user_id": user_id,
            "amount": 100 + i,
            "merchant_category": "grocery",
            "hour": 12,
            "day_of_week": 1
        }
        for i in range(15)
    ]

    training_data = {
        "user_id": user_id,
        "transactions": transactions
    }

    resp = requests.post(f"{BASE_URL}/train-user", json=training_data)
    assert resp.status_code == 200
    print("‚úÖ Training endpoint passed")

    # Test detect-fraud endpoint
    test_txn = {
        "user_id": user_id,
        "amount": 5000,
        "merchant_category": "electronics",
        "hour": 2,
        "day_of_week": 6
    }
    resp = requests.post(f"{BASE_URL}/detect-fraud", json=test_txn)
    assert resp.status_code == 200
    print(f"‚úÖ Detect fraud endpoint passed with risk level {resp.json()['risk_level']}")

if __name__ == '__main__':
    test_health_check()
    test_docs_available()
    test_training_endpoint()
    print("All basic tests passed successfully!")
</file>

<file path="ml-service/utils/explainability.py">
import shap
import numpy as np

class Explainability:
    def __init__(self, model, scaler):
        self.model = model
        self.scaler = scaler
        self.explainer = None
        self._init_explainer()

    def _init_explainer(self):
        try:
            self.explainer = shap.Explainer(self.model)
        except Exception as e:
            print(f"Error creating SHAP explainer: {e}")
            self.explainer = None

    def explain(self, X):
        if self.explainer is None:
            return None
        X_scaled = self.scaler.transform(X)
        shap_values = self.explainer(X_scaled)
        return shap_values

    def get_feature_importance(self, shap_values, feature_names):
        if shap_values is None:
            return None
        importance = np.abs(shap_values.values).mean(axis=0)
        return dict(zip(feature_names, importance))
</file>

<file path="ml-service/utils/model_persistence.py">
import os
import pickle
import logging
from typing import Optional, List, Tuple, Dict, Any

logger = logging.getLogger(__name__)

class ModelPersistence:
    """Handle saving and loading of ML models and associated data"""
    
    def __init__(self, models_dir: str = "saved_models"):
        """
        Initialize model persistence handler
        
        Args:
            models_dir: Directory to save models
        """
        self.models_dir = models_dir
        
        # Create directory if it doesn't exist
        try:
            os.makedirs(models_dir, exist_ok=True)
            logger.info(f"Model persistence initialized with directory: {models_dir}")
        except Exception as e:
            logger.error(f"Failed to create models directory {models_dir}: {e}")
            raise
    
    def save_model(self, user_id: str, profile: Dict, model: Any, scaler: Any) -> bool:
        """
        Save model and related data for a user
        
        Args:
            user_id: Unique user identifier
            profile: User profile dictionary
            model: Trained ML model
            scaler: Fitted scaler
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            model_path = os.path.join(self.models_dir, f"{user_id}.pkl")
            
            # Package all data together
            model_data = {
                'user_id': user_id,
                'profile': profile,
                'model': model,
                'scaler': scaler,
                'saved_at': os.path.getmtime(model_path) if os.path.exists(model_path) else None
            }
            
            # Save using pickle with highest protocol for efficiency
            with open(model_path, 'wb') as f:
                pickle.dump(model_data, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            # Verify the file was created
            if os.path.exists(model_path):
                file_size = os.path.getsize(model_path)
                logger.info(f"Saved model for {user_id} at {model_path} ({file_size} bytes)")
                return True
            else:
                logger.error(f"Model file not created for {user_id}")
                return False
                
        except Exception as e:
            logger.error(f"Failed to save model for {user_id}: {e}")
            return False
    
    def load_model(self, user_id: str) -> Tuple[Optional[Dict], Optional[Any], Optional[Any]]:
        """
        Load model and related data for a user
        
        Args:
            user_id: Unique user identifier
            
        Returns:
            Tuple of (profile, model, scaler) or (None, None, None) if failed
        """
        try:
            model_path = os.path.join(self.models_dir, f"{user_id}.pkl")
            
            if not os.path.exists(model_path):
                logger.warning(f"Model file not found for {user_id} at {model_path}")
                return None, None, None
            
            # Load the pickled data
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            # Extract components
            profile = model_data.get('profile')
            model = model_data.get('model')
            scaler = model_data.get('scaler')
            
            # Validate loaded data
            if profile is None or model is None or scaler is None:
                logger.error(f"Incomplete model data for {user_id}")
                return None, None, None
            
            logger.info(f"Loaded model for {user_id} from {model_path}")
            return profile, model, scaler
            
        except Exception as e:
            logger.error(f"Failed to load model for {user_id}: {e}")
            return None, None, None
    
    def list_models(self) -> List[str]:
        """
        List all available saved models
        
        Returns:
            List of user IDs that have saved models
        """
        try:
            if not os.path.exists(self.models_dir):
                return []
            
            # Get all .pkl files and extract user IDs
            pkl_files = [f for f in os.listdir(self.models_dir) if f.endswith('.pkl')]
            user_ids = [f.replace('.pkl', '') for f in pkl_files]
            
            logger.info(f"Found {len(user_ids)} saved models: {user_ids}")
            return user_ids
            
        except Exception as e:
            logger.error(f"Failed to list models: {e}")
            return []
    
    def delete_model(self, user_id: str) -> bool:
        """
        Delete saved model for a user
        
        Args:
            user_id: Unique user identifier
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            model_path = os.path.join(self.models_dir, f"{user_id}.pkl")
            
            if os.path.exists(model_path):
                os.remove(model_path)
                logger.info(f"Deleted model for {user_id}")
                return True
            else:
                logger.warning(f"Model file not found for deletion: {user_id}")
                return False
                
        except Exception as e:
            logger.error(f"Failed to delete model for {user_id}: {e}")
            return False
    
    def get_model_info(self, user_id: str) -> Optional[Dict]:
        """
        Get metadata about a saved model
        
        Args:
            user_id: Unique user identifier
            
        Returns:
            Dictionary with model metadata or None if not found
        """
        try:
            model_path = os.path.join(self.models_dir, f"{user_id}.pkl")
            
            if not os.path.exists(model_path):
                return None
            
            # Get file stats
            file_stats = os.stat(model_path)
            
            return {
                'user_id': user_id,
                'file_path': model_path,
                'file_size_bytes': file_stats.st_size,
                'created_at': file_stats.st_ctime,
                'modified_at': file_stats.st_mtime,
                'accessible': os.access(model_path, os.R_OK)
            }
            
        except Exception as e:
            logger.error(f"Failed to get model info for {user_id}: {e}")
            return None
    
    def cleanup_old_models(self, max_age_days: int = 30) -> int:
        """
        Remove models older than specified days
        
        Args:
            max_age_days: Maximum age in days
            
        Returns:
            Number of models deleted
        """
        try:
            if not os.path.exists(self.models_dir):
                return 0
            
            import time
            current_time = time.time()
            max_age_seconds = max_age_days * 24 * 60 * 60
            deleted_count = 0
            
            for filename in os.listdir(self.models_dir):
                if filename.endswith('.pkl'):
                    file_path = os.path.join(self.models_dir, filename)
                    file_age = current_time - os.path.getmtime(file_path)
                    
                    if file_age > max_age_seconds:
                        os.remove(file_path)
                        deleted_count += 1
                        logger.info(f"Deleted old model: {filename}")
            
            logger.info(f"Cleanup completed: {deleted_count} old models removed")
            return deleted_count
            
        except Exception as e:
            logger.error(f"Failed to cleanup old models: {e}")
            return 0
</file>

<file path="ml-service/utils/monitoring.py">
import logging
import time
import json
from datetime import datetime, timedelta
from typing import Dict, List
from collections import defaultdict, deque
import threading

class FraudGuardMonitor:
    """Comprehensive monitoring and alerting system"""
    
    def __init__(self):
        self.metrics = {
            'total_requests': 0,
            'fraud_detected': 0,
            'false_positives': 0,
            'processing_times': deque(maxlen=1000),
            'error_count': 0,
            'model_predictions': defaultdict(int),
            'hourly_stats': defaultdict(lambda: {'requests': 0, 'fraud': 0}),
            'user_activity': defaultdict(int),
            'high_risk_transactions': []
        }
        
        self.alerts = {
            'high_fraud_rate': False,
            'slow_response': False,
            'model_errors': False,
            'unusual_activity': False
        }
        
        self.thresholds = {
            'max_fraud_rate': 0.15,  # 15% fraud rate threshold
            'max_response_time': 200,  # 200ms response time
            'max_error_rate': 0.05,   # 5% error rate
            'min_requests_for_alert': 100
        }
        
        self.logger = logging.getLogger("fraudguard_monitor")
        self._setup_logging()
        
    def _setup_logging(self):
        """Setup monitoring-specific logging"""
        handler = logging.FileHandler('fraudguard_monitoring.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
    
    def record_transaction(self, user_id: str, result: Dict, processing_time: float):
        """Record transaction metrics"""
        self.metrics['total_requests'] += 1
        self.metrics['user_activity'][user_id] += 1
        self.metrics['processing_times'].append(processing_time)
        
        # Record fraud detection
        if result.get('is_suspicious', False):
            self.metrics['fraud_detected'] += 1
            
            # Store high-risk transactions for analysis
            if result.get('risk_level') in ['HIGH', 'CRITICAL']:
                self.metrics['high_risk_transactions'].append({
                    'user_id': user_id,
                    'timestamp': datetime.now().isoformat(),
                    'risk_level': result['risk_level'],
                    'anomaly_score': result.get('anomaly_score', 0)
                })
        
        # Hourly statistics
        hour = datetime.now().hour
        self.metrics['hourly_stats'][hour]['requests'] += 1
        if result.get('is_suspicious', False):
            self.metrics['hourly_stats'][hour]['fraud'] += 1
        
        # Check for alerts
        self._check_alerts()
        
    def record_error(self, error_type: str, details: str):
        """Record system errors"""
        self.metrics['error_count'] += 1
        self.logger.error(f"Error recorded: {error_type} - {details}")
        self._check_alerts()
    
    def record_model_prediction(self, model_name: str, prediction: int):
        """Record individual model predictions"""
        self.metrics['model_predictions'][model_name] += prediction
    
    def _check_alerts(self):
        """Check if any alert thresholds are exceeded"""
        if self.metrics['total_requests'] < self.thresholds['min_requests_for_alert']:
            return
        
        # High fraud rate alert
        fraud_rate = self.metrics['fraud_detected'] / self.metrics['total_requests']
        if fraud_rate > self.thresholds['max_fraud_rate']:
            if not self.alerts['high_fraud_rate']:
                self._trigger_alert('high_fraud_rate', f"Fraud rate {fraud_rate:.1%} exceeds threshold")
                self.alerts['high_fraud_rate'] = True
        else:
            self.alerts['high_fraud_rate'] = False
        
        # Slow response alert
        if len(self.metrics['processing_times']) > 50:
            avg_response = sum(list(self.metrics['processing_times'])[-50:]) / 50
            if avg_response > self.thresholds['max_response_time']:
                if not self.alerts['slow_response']:
                    self._trigger_alert('slow_response', f"Avg response time {avg_response:.1f}ms exceeds threshold")
                    self.alerts['slow_response'] = True
            else:
                self.alerts['slow_response'] = False
        
        # Error rate alert
        error_rate = self.metrics['error_count'] / self.metrics['total_requests']
        if error_rate > self.thresholds['max_error_rate']:
            if not self.alerts['model_errors']:
                self._trigger_alert('model_errors', f"Error rate {error_rate:.1%} exceeds threshold")
                self.alerts['model_errors'] = True
        else:
            self.alerts['model_errors'] = False
    
    def _trigger_alert(self, alert_type: str, message: str):
        """Trigger an alert"""
        alert_data = {
            'type': alert_type,
            'message': message,
            'timestamp': datetime.now().isoformat(),
            'metrics_snapshot': self.get_current_metrics()
        }
        
        self.logger.warning(f"ALERT TRIGGERED: {alert_type} - {message}")
        
        # In production, you would send this to monitoring systems
        # like Slack, email, PagerDuty, etc.
        print(f"üö® ALERT: {alert_type} - {message}")
    
    def get_current_metrics(self) -> Dict:
        """Get current system metrics"""
        if self.metrics['total_requests'] > 0:
            fraud_rate = self.metrics['fraud_detected'] / self.metrics['total_requests']
            error_rate = self.metrics['error_count'] / self.metrics['total_requests']
        else:
            fraud_rate = 0
            error_rate = 0
        
        processing_times = list(self.metrics['processing_times'])
        avg_response_time = sum(processing_times) / len(processing_times) if processing_times else 0
        
        return {
            'total_requests': self.metrics['total_requests'],
            'fraud_detected': self.metrics['fraud_detected'],
            'fraud_rate': fraud_rate,
            'error_count': self.metrics['error_count'],
            'error_rate': error_rate,
            'avg_response_time_ms': avg_response_time,
            'active_alerts': [k for k, v in self.alerts.items() if v],
            'top_active_users': dict(sorted(self.metrics['user_activity'].items(), 
                                          key=lambda x: x[1], reverse=True)[:5]),
            'recent_high_risk_count': len([t for t in self.metrics['high_risk_transactions'] 
                                         if datetime.fromisoformat(t['timestamp']) > 
                                         datetime.now() - timedelta(hours=1)])
        }
    
    def get_detailed_analytics(self) -> Dict:
        """Get detailed analytics dashboard data"""
        metrics = self.get_current_metrics()
        
        # Hourly breakdown
        hourly_data = []
        for hour in range(24):
            stats = self.metrics['hourly_stats'][hour]
            if stats['requests'] > 0:
                hourly_fraud_rate = stats['fraud'] / stats['requests']
            else:
                hourly_fraud_rate = 0
            
            hourly_data.append({
                'hour': hour,
                'requests': stats['requests'],
                'fraud_count': stats['fraud'],
                'fraud_rate': hourly_fraud_rate
            })
        
        # Model performance comparison
        model_performance = {}
        total_model_predictions = sum(self.metrics['model_predictions'].values())
        for model, predictions in self.metrics['model_predictions'].items():
            if total_model_predictions > 0:
                model_performance[model] = predictions / total_model_predictions
            else:
                model_performance[model] = 0
        
        return {
            'current_metrics': metrics,
            'hourly_breakdown': hourly_data,
            'model_performance': model_performance,
            'recent_high_risk_transactions': self.metrics['high_risk_transactions'][-10:],
            'alert_history': list(self.alerts.keys()),
            'system_health': self._calculate_system_health()
        }
    
    def _calculate_system_health(self) -> str:
        """Calculate overall system health score"""
        health_score = 100
        
        # Deduct points for active alerts
        active_alerts = sum(1 for alert in self.alerts.values() if alert)
        health_score -= active_alerts * 20
        
        # Deduct for high error rate
        if self.metrics['total_requests'] > 0:
            error_rate = self.metrics['error_count'] / self.metrics['total_requests']
            health_score -= error_rate * 100
        
        # Deduct for slow response times
        if len(self.metrics['processing_times']) > 10:
            avg_response = sum(list(self.metrics['processing_times'])[-10:]) / 10
            if avg_response > 100:
                health_score -= 10
        
        health_score = max(0, min(100, health_score))
        
        if health_score >= 90:
            return "EXCELLENT"
        elif health_score >= 70:
            return "GOOD"
        elif health_score >= 50:
            return "FAIR"
        else:
            return "POOR"

# Global monitor instance
monitor = FraudGuardMonitor()
</file>

<file path="ml-service/.gitignore">
venv/
__pycache__/
*.pyc
saved_models/
</file>

<file path="ml-service/advanced_sample.csv">
user_id,amount,merchant_category,hour,day,location,is_fraud,timestamp
USER_001,129.97,retail,9,3,normal_area,False,2025-08-27T02:20:32.333240
USER_001,283.28,gas,19,3,normal_area,False,2025-08-27T02:20:32.333281
USER_001,191.03,gas,14,2,normal_area,False,2025-08-27T02:20:32.333289
USER_001,160.03,retail,15,4,normal_area,False,2025-08-27T02:20:32.333294
USER_001,195.42,grocery,12,3,normal_area,False,2025-08-27T02:20:32.333299
USER_001,260.25,restaurant,10,4,normal_area,False,2025-08-27T02:20:32.333304
USER_001,245.41,retail,9,1,normal_area,False,2025-08-27T02:20:32.333308
USER_001,236.25,restaurant,16,0,normal_area,False,2025-08-27T02:20:32.333312
USER_001,119.13,gas,20,3,normal_area,False,2025-08-27T02:20:32.333317
USER_001,156.03,restaurant,15,0,normal_area,False,2025-08-27T02:20:32.333323
USER_001,231.31,restaurant,10,2,normal_area,False,2025-08-27T02:20:32.333330
USER_001,166.58,gas,8,2,normal_area,False,2025-08-27T02:20:32.333336
USER_001,1703.29,cash_advance,23,5,suspicious_area,True,2025-08-27T02:20:32.333347
USER_001,178.83,retail,21,3,normal_area,False,2025-08-27T02:20:32.333352
USER_001,259.68,restaurant,11,2,normal_area,False,2025-08-27T02:20:32.333356
USER_001,164.02,grocery,10,3,normal_area,False,2025-08-27T02:20:32.333361
USER_001,182.1,retail,12,2,normal_area,False,2025-08-27T02:20:32.333365
USER_001,250.41,gas,16,0,normal_area,False,2025-08-27T02:20:32.333371
USER_001,218.0,restaurant,16,4,normal_area,False,2025-08-27T02:20:32.333375
USER_001,162.23,grocery,7,4,normal_area,False,2025-08-27T02:20:32.333380
USER_001,121.15,gas,12,2,normal_area,False,2025-08-27T02:20:32.333384
USER_001,209.96,restaurant,14,2,normal_area,False,2025-08-27T02:20:32.333388
USER_001,312.88,grocery,8,3,normal_area,False,2025-08-27T02:20:32.333393
USER_001,181.13,grocery,21,0,normal_area,False,2025-08-27T02:20:32.333397
USER_001,146.85,retail,21,4,normal_area,False,2025-08-27T02:20:32.333401
USER_001,2619.7,travel,3,5,suspicious_area,True,2025-08-27T02:20:32.333406
USER_001,225.75,grocery,16,3,normal_area,False,2025-08-27T02:20:32.333411
USER_001,267.77,retail,12,1,normal_area,False,2025-08-27T02:20:32.333415
USER_001,204.05,gas,9,4,normal_area,False,2025-08-27T02:20:32.333420
USER_001,252.48,gas,12,2,normal_area,False,2025-08-27T02:20:32.333424
</file>

<file path="ml-service/app.py">
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse, FileResponse
from fastapi.encoders import jsonable_encoder
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, ConfigDict
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest, RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import joblib
import shap
from typing import List, Dict, Optional
import logging
from datetime import datetime, timedelta
import json
import os
from collections import defaultdict, deque
import threading
import traceback

# Import the model persistence utilities
from utils.model_persistence import ModelPersistence

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("fraudguard_ml")

# Utility function to convert numpy types
def convert_numpy_types(obj):
    """Convert numpy types to native Python types recursively"""
    if isinstance(obj, np.generic):
        return obj.item()
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

# Monitoring System
class FraudGuardMonitor:
    """Comprehensive monitoring and alerting system"""
    
    def __init__(self):
        self.metrics = {
            'total_requests': 0,
            'fraud_detected': 0,
            'false_positives': 0,
            'processing_times': deque(maxlen=1000),
            'error_count': 0,
            'model_predictions': defaultdict(int),
            'hourly_stats': defaultdict(lambda: {'requests': 0, 'fraud': 0}),
            'user_activity': defaultdict(int),
            'high_risk_transactions': []
        }
        
        self.alerts = {
            'high_fraud_rate': False,
            'slow_response': False,
            'model_errors': False,
            'unusual_activity': False
        }
        
        self.thresholds = {
            'max_fraud_rate': 0.15,
            'max_response_time': 200,
            'max_error_rate': 0.05,
            'min_requests_for_alert': 50
        }
        
        self.logger = logging.getLogger("fraudguard_monitor")
        
    def record_transaction(self, user_id: str, result: Dict, processing_time: float):
        """Record transaction metrics"""
        self.metrics['total_requests'] += 1
        self.metrics['user_activity'][user_id] += 1
        self.metrics['processing_times'].append(processing_time)
        
        if result.get('is_suspicious', False):
            self.metrics['fraud_detected'] += 1
            
            if result.get('risk_level') in ['HIGH', 'CRITICAL']:
                self.metrics['high_risk_transactions'].append({
                    'user_id': user_id,
                    'timestamp': datetime.now().isoformat(),
                    'risk_level': result['risk_level'],
                    'anomaly_score': result.get('anomaly_score', 0)
                })
        
        hour = datetime.now().hour
        self.metrics['hourly_stats'][hour]['requests'] += 1
        if result.get('is_suspicious', False):
            self.metrics['hourly_stats'][hour]['fraud'] += 1
        
        self._check_alerts()
        
    def record_error(self, error_type: str, details: str):
        """Record system errors"""
        self.metrics['error_count'] += 1
        self.logger.error(f"Error recorded: {error_type} - {details}")
        self._check_alerts()
    
    def _check_alerts(self):
        """Check if any alert thresholds are exceeded"""
        if self.metrics['total_requests'] < self.thresholds['min_requests_for_alert']:
            return
        
        fraud_rate = self.metrics['fraud_detected'] / self.metrics['total_requests']
        if fraud_rate > self.thresholds['max_fraud_rate']:
            if not self.alerts['high_fraud_rate']:
                self._trigger_alert('high_fraud_rate', f"Fraud rate {fraud_rate:.1%} exceeds threshold")
                self.alerts['high_fraud_rate'] = True
        else:
            self.alerts['high_fraud_rate'] = False
    
    def _trigger_alert(self, alert_type: str, message: str):
        """Trigger an alert"""
        self.logger.warning(f"ALERT TRIGGERED: {alert_type} - {message}")
        print(f"üö® ALERT: {alert_type} - {message}")
    
    def get_current_metrics(self) -> Dict:
        """Get current system metrics"""
        if self.metrics['total_requests'] > 0:
            fraud_rate = self.metrics['fraud_detected'] / self.metrics['total_requests']
            error_rate = self.metrics['error_count'] / self.metrics['total_requests']
        else:
            fraud_rate = 0
            error_rate = 0
        
        processing_times = list(self.metrics['processing_times'])
        avg_response_time = sum(processing_times) / len(processing_times) if processing_times else 0
        
        return {
            'total_requests': self.metrics['total_requests'],
            'fraud_detected': self.metrics['fraud_detected'],
            'fraud_rate': fraud_rate,
            'error_count': self.metrics['error_count'],
            'error_rate': error_rate,
            'avg_response_time_ms': avg_response_time,
            'active_alerts': [k for k, v in self.alerts.items() if v],
            'top_active_users': dict(sorted(self.metrics['user_activity'].items(), 
                                          key=lambda x: x[1], reverse=True)[:5]),
            'recent_high_risk_count': len([t for t in self.metrics['high_risk_transactions'] 
                                         if datetime.fromisoformat(t['timestamp']) > 
                                         datetime.now() - timedelta(hours=1)])
        }

app = FastAPI(
    title="üõ°Ô∏è FraudGuard ML Service",
    version="2.3.0",
    description="Complete AI-powered fraud detection with ensemble models, SHAP explainability, real-time monitoring, and visual dashboard",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Add CORS middleware for dashboard
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify your domain
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global Exception Handler for Better Debugging
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    tb_str = ''.join(traceback.format_tb(exc.__traceback__))
    logger.error(f"üö® UNHANDLED EXCEPTION: {exc}")
    logger.error(f"üìç TRACEBACK:\n{tb_str}")
    return JSONResponse(
        status_code=500,
        content={"detail": "Internal Server Error", "error": str(exc), "traceback": tb_str}
    )

# Pydantic Models with V2 compatibility
class Transaction(BaseModel):
    model_config = ConfigDict(protected_namespaces=())
    
    user_id: str
    amount: float
    merchant_category: str
    hour: int
    day_of_week: int
    location: str = "unknown"
    merchant_id: Optional[str] = None
    transaction_id: Optional[str] = None

class TrainingData(BaseModel):
    model_config = ConfigDict(protected_namespaces=())
    
    user_id: str
    transactions: List[Transaction]

class FraudResult(BaseModel):
    model_config = ConfigDict(protected_namespaces=())
    
    user_id: str
    transaction_id: Optional[str] = None
    is_suspicious: bool
    anomaly_score: float
    risk_level: str
    explanation: List[str]
    confidence: float
    processing_time_ms: float
    shap_analysis: Optional[Dict] = None
    ensemble_analysis: Optional[Dict] = None

class UserProfile(BaseModel):
    model_config = ConfigDict(protected_namespaces=())
    
    user_id: str
    total_transactions: int
    avg_amount: float
    std_amount: float
    common_categories: Dict[str, int]
    active_hours: List[int]
    risk_indicators: Dict[str, float]
    model_trained: bool
    created_at: str

# SHAP Explainability Class
class SHAPExplainer:
    """Enhanced SHAP integration for fraud detection explainability"""
    
    def __init__(self):
        self.explainers = {}
        self.feature_names = ['amount', 'hour', 'day_of_week', 'category_encoded', 'is_weekend', 'is_night']
    
    def create_explainer(self, user_id: str, model, training_data: np.ndarray):
        """Create SHAP explainer for a specific user's model"""
        try:
            explainer = shap.Explainer(model, training_data)
            self.explainers[user_id] = explainer
            logger.info(f"‚úÖ Created SHAP explainer for {user_id}")
            return True
        except Exception as e:
            logger.warning(f"Failed to create SHAP explainer for {user_id}: {e}")
            return False
    
    def explain_prediction(self, user_id: str, features: np.ndarray) -> Dict:
        """Generate SHAP explanations for a prediction"""
        if user_id not in self.explainers:
            return {"shap_available": False, "error": "SHAP explainer not found"}
        
        try:
            explainer = self.explainers[user_id]
            shap_values = explainer(features)
            
            if hasattr(shap_values, 'values'):
                values = shap_values.values[0]
            else:
                values = shap_values[0]
            
            feature_importance = {}
            explanations = []
            
            for i, (feature_name, shap_val) in enumerate(zip(self.feature_names, values)):
                feature_importance[feature_name] = float(shap_val)
                
                if abs(shap_val) > 0.01:
                    impact = "increases" if shap_val > 0 else "decreases" 
                    strength = "strongly" if abs(shap_val) > 0.1 else "moderately"
                    explanations.append(f"üî¨ {feature_name}: {strength} {impact} fraud risk ({shap_val:.3f})")
            
            return {
                "shap_available": True,
                "feature_importance": feature_importance,
                "explanations": explanations,
                "total_impact": float(np.sum(values)),
                "most_important_feature": self.feature_names[np.argmax(np.abs(values))]
            }
            
        except Exception as e:
            logger.error(f"SHAP explanation failed for {user_id}: {e}")
            return {"shap_available": False, "error": str(e)}

# FIXED: Ensemble Fraud Detector with proper type conversion
class EnsembleFraudDetector:
    """Ensemble fraud detection with numpy type conversion fixes"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        
    def prepare_training_data_with_synthetic_fraud(self, transactions: List[Dict]) -> tuple:
        """Create training data with synthetic fraud examples"""
        df = pd.DataFrame(transactions)
        
        features = []
        labels = []
        
        for _, row in df.iterrows():
            feature_vector = [
                row['amount'],
                row['hour'],
                row['day_of_week'],
                hash(row['merchant_category']) % 1000,
                1 if row['day_of_week'] in [5, 6] else 0,
                1 if row['hour'] in [22, 23, 0, 1, 2, 3, 4, 5] else 0,
            ]
            features.append(feature_vector)
            labels.append(0)
        
        # Add synthetic fraud examples
        avg_amount = df['amount'].mean()
        for i in range(len(transactions) // 3):
            fraud_feature = [
                avg_amount * np.random.uniform(3, 10),
                np.random.choice([1, 2, 3, 23]),
                np.random.choice([5, 6]),
                hash('electronics') % 1000,
                1,
                1,
            ]
            features.append(fraud_feature)
            labels.append(1)
        
        return np.array(features), np.array(labels)
    
    def train_ensemble(self, user_id: str, transactions: List[Dict]):
        """Train simplified ensemble"""
        logger.info(f"ü§ñ Training simplified ensemble for {user_id}")
        
        try:
            X, y = self.prepare_training_data_with_synthetic_fraud(transactions)
            
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            self.scalers[user_id] = scaler
            
            model = RandomForestClassifier(
                n_estimators=100, 
                max_depth=8, 
                random_state=42,
                class_weight='balanced'
            )
            model.fit(X_scaled, y)
            
            self.models[user_id] = model
            
            fraud_rate = np.mean(y)
            logger.info(f"‚úÖ Simplified ensemble training completed. Synthetic fraud rate: {fraud_rate:.1%}")
            
            return {
                'models_trained': ['random_forest'],
                'fraud_rate': float(fraud_rate),  # Convert to Python float
                'total_samples': int(len(X))  # Convert to Python int
            }
            
        except Exception as e:
            logger.error(f"Ensemble training failed for {user_id}: {e}")
            return None
    
    def predict_ensemble(self, user_id: str, transaction: Dict, isolation_score: float = None) -> Dict:
        """FIXED: Make ensemble prediction with proper type conversion"""
        if user_id not in self.models:
            return None
        
        try:
            features = [
                transaction['amount'],
                transaction['hour'],
                transaction['day_of_week'],
                hash(transaction['merchant_category']) % 1000,
                1 if transaction['day_of_week'] in [5, 6] else 0,
                1 if transaction['hour'] in [22, 23, 0, 1, 2, 3, 4, 5] else 0,
            ]
            
            features_scaled = self.scalers[user_id].transform([features])
            
            model = self.models[user_id]
            pred_proba = model.predict_proba(features_scaled)[0]
            fraud_proba = pred_proba[1] if len(pred_proba) > 1 else 0
            
            # CRITICAL FIX: Convert all numpy types to native Python types
            return {
                'ensemble_score': float(fraud_proba),  # Convert to Python float
                'is_fraud': bool(fraud_proba > 0.5),   # Convert to Python bool
                'model_predictions': {'random_forest': int(fraud_proba > 0.5)},  # Convert to Python int
                'model_probabilities': {'random_forest': float(fraud_proba)},   # Convert to Python float
                'confidence': float(abs(fraud_proba - 0.5) * 2)  # Convert to Python float
            }
            
        except Exception as e:
            logger.error(f"Ensemble prediction failed for {user_id}: {e}")
            return None

# Enhanced User Behavioral Profile Manager
class FraudGuardML:
    def __init__(self):
        self.profiles = {}
        self.models = {}
        self.scalers = {}
        self.training_data = {}
        self.shap_explainer = SHAPExplainer()
        self.ensemble_detector = EnsembleFraudDetector()
        self.ensemble_trained = {}
        self.feature_columns = ['amount', 'hour', 'day_of_week', 'category_encoded', 'is_weekend', 'is_night']
        
    def create_comprehensive_profile(self, user_id: str, transactions: List[Dict]) -> Dict:
        """Create detailed behavioral profile for user with ensemble and SHAP integration"""
        logger.info(f"üèóÔ∏è Starting profile creation for {user_id}")
        
        df = pd.DataFrame(transactions)
        
        # Basic statistics
        profile = {
            'user_id': user_id,
            'total_transactions': len(transactions),
            'avg_amount': float(df['amount'].mean()),
            'std_amount': float(df['amount'].std()),
            'median_amount': float(df['amount'].median()),
            'min_amount': float(df['amount'].min()),
            'max_amount': float(df['amount'].max()),
            
            'common_categories': df['merchant_category'].value_counts().head(5).to_dict(),
            'active_hours': df['hour'].value_counts().head(8).index.tolist(),
            'active_days': df['day_of_week'].value_counts().head(5).index.tolist(),
            
            'weekend_ratio': float(len(df[df['day_of_week'].isin([5, 6])]) / len(df)),
            'night_ratio': float(len(df[df['hour'].isin([22, 23, 0, 1, 2, 3, 4, 5])]) / len(df)),
            'high_amount_ratio': float(len(df[df['amount'] > df['amount'].quantile(0.9)]) / len(df)),
            
            'spending_velocity': float(len(transactions) / 30),
            'avg_daily_amount': float(df['amount'].sum() / 30),
            
            'created_at': datetime.now().isoformat(),
            'last_updated': datetime.now().isoformat(),
            'model_version': '2.3.0'
        }
        
        logger.info("üìä Extracting features...")
        features = self._extract_advanced_features(df)
        
        logger.info("üîÑ Training Isolation Forest...")
        scaler = StandardScaler()
        scaled_features = scaler.fit_transform(features)
        
        model = IsolationForest(
            contamination=0.1,
            n_estimators=200,
            max_samples='auto',
            max_features=1.0,
            bootstrap=True,
            random_state=42,
            n_jobs=-1
        )
        model.fit(scaled_features)
        
        self.profiles[user_id] = profile
        self.models[user_id] = model
        self.scalers[user_id] = scaler
        self.training_data[user_id] = scaled_features
        
        logger.info("üî¨ Creating SHAP explainer...")
        self.shap_explainer.create_explainer(user_id, model, scaled_features)
        
        logger.info("ü§ñ Training ensemble models...")
        try:
            ensemble_result = self.ensemble_detector.train_ensemble(user_id, transactions)
            if ensemble_result:
                self.ensemble_trained[user_id] = True
                profile['ensemble_models'] = ensemble_result['models_trained']
                profile['ensemble_fraud_rate'] = ensemble_result['fraud_rate']
            else:
                self.ensemble_trained[user_id] = False
        except Exception as e:
            logger.warning(f"Ensemble training failed for {user_id}: {e}")
            self.ensemble_trained[user_id] = False
        
        logger.info(f"‚úÖ Profile creation completed for {user_id}")
        return profile
    
    def detect_advanced_fraud(self, user_id: str, transaction: Dict) -> Dict:
        """Advanced fraud detection with ensemble models, SHAP explanations, and monitoring"""
        start_time = datetime.now()
        
        if user_id not in self.models:
            return {
                'anomaly_score': 0.0,
                'is_suspicious': False,
                'risk_level': 'UNKNOWN',
                'explanation': ['User profile not found - please train model first'],
                'confidence': 0.0,
                'processing_time_ms': 0.0,
                'shap_analysis': None,
                'ensemble_analysis': None
            }
        
        model = self.models[user_id]
        scaler = self.scalers[user_id]
        profile = self.profiles[user_id]
        
        features = self._extract_single_transaction_features(transaction)
        scaled_features = scaler.transform([features])
        
        isolation_score = model.decision_function(scaled_features)[0]
        normalized_score = max(0, min(1, (0.5 - isolation_score)))
        
        rule_score = self._apply_business_rules(transaction, profile)
        
        ensemble_result = None
        final_score = (normalized_score * 0.7) + (rule_score * 0.3)
        
        if user_id in self.ensemble_trained and self.ensemble_trained[user_id]:
            try:
                ensemble_result = self.ensemble_detector.predict_ensemble(
                    user_id, transaction, normalized_score
                )
                
                if ensemble_result:
                    final_score = ensemble_result['ensemble_score']
                    
            except Exception as e:
                logger.warning(f"Ensemble prediction failed for {user_id}: {e}")
        
        shap_analysis = self.shap_explainer.explain_prediction(user_id, scaled_features)
        
        explanations = self._generate_comprehensive_explanations(transaction, profile, normalized_score, rule_score)
        
        if shap_analysis.get('shap_available', False):
            explanations.append("üî¨ AI Model Feature Analysis:")
            explanations.extend(shap_analysis['explanations'][:3])
            most_important = shap_analysis.get('most_important_feature', 'unknown')
            explanations.append(f"üéØ Most influential factor: {most_important}")
        
        if ensemble_result:
            explanations.append("ü§ñ Ensemble Model Analysis:")
            explanations.append(f"üìä Ensemble confidence: {ensemble_result['confidence']:.3f}")
        
        if final_score > 0.9:
            risk_level = "CRITICAL"
            is_suspicious = True
        elif final_score > 0.7:
            risk_level = "HIGH"
            is_suspicious = True
        elif final_score > 0.5:
            risk_level = "MEDIUM"
            is_suspicious = True
        else:
            risk_level = "LOW"
            is_suspicious = False
        
        confidence = abs(final_score - 0.5) * 2
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        result = {
            'anomaly_score': float(final_score),  # Ensure Python float
            'is_suspicious': bool(is_suspicious),  # Ensure Python bool
            'risk_level': risk_level,
            'explanation': explanations,
            'confidence': float(confidence),  # Ensure Python float
            'processing_time_ms': float(processing_time),  # Ensure Python float
            'shap_analysis': shap_analysis,
            'ensemble_analysis': ensemble_result,
            'model_scores': {
                'isolation_forest': float(normalized_score),  # Ensure Python float
                'business_rules': float(rule_score),  # Ensure Python float
                'ensemble': float(final_score) if ensemble_result else None,  # Ensure Python float
                'combined': float(final_score)  # Ensure Python float
            }
        }
        
        monitor.record_transaction(user_id, result, processing_time)
        
        return result
    
    def _extract_advanced_features(self, df: pd.DataFrame) -> np.ndarray:
        """Extract comprehensive feature set"""
        features = []
        
        for _, row in df.iterrows():
            feature_vector = [
                row['amount'],
                row['hour'],
                row['day_of_week'],
                hash(row['merchant_category']) % 1000,
                1 if row['day_of_week'] in [5, 6] else 0,
                1 if row['hour'] in [22, 23, 0, 1, 2, 3, 4, 5] else 0,
            ]
            features.append(feature_vector)
        
        return np.array(features)
    
    def _extract_single_transaction_features(self, transaction: Dict) -> List[float]:
        """Extract features from single transaction"""
        return [
            transaction['amount'],
            transaction['hour'],
            transaction['day_of_week'],
            hash(transaction['merchant_category']) % 1000,
            1 if transaction['day_of_week'] in [5, 6] else 0,
            1 if transaction['hour'] in [22, 23, 0, 1, 2, 3, 4, 5] else 0
        ]
    
    def _apply_business_rules(self, transaction: Dict, profile: Dict) -> float:
        """Apply business rules for additional fraud detection"""
        rule_score = 0.0
        
        if transaction['amount'] > 5000:
            rule_score += 0.3
        
        if transaction['amount'] > profile['avg_amount'] * 10:
            rule_score += 0.4
        
        if transaction['hour'] in [0, 1, 2, 3, 4, 5]:
            rule_score += 0.2
        
        high_risk_categories = ['electronics', 'jewelry', 'travel', 'cash_advance']
        if transaction['merchant_category'] in high_risk_categories:
            rule_score += 0.2
        
        if transaction['day_of_week'] in [5, 6] and transaction['hour'] in [22, 23, 0, 1, 2]:
            rule_score += 0.15
        
        return min(1.0, rule_score)
    
    def _generate_comprehensive_explanations(self, transaction: Dict, profile: Dict, 
                                           ml_score: float, rule_score: float) -> List[str]:
        """Generate detailed human-readable explanations"""
        explanations = []
        
        amount = transaction['amount']
        avg_amount = profile['avg_amount']
        std_amount = profile['std_amount']
        
        if amount > avg_amount + 3 * std_amount:
            explanations.append(
                f"‚ö†Ô∏è Amount ${amount:.2f} is {amount/avg_amount:.1f}x higher than usual (avg: ${avg_amount:.2f})"
            )
        elif amount > avg_amount + 2 * std_amount:
            explanations.append(
                f"üí° Amount ${amount:.2f} is significantly higher than typical ${avg_amount:.2f}"
            )
        
        hour = transaction['hour']
        active_hours = profile['active_hours']
        
        if hour not in active_hours[:5]:
            if hour in [0, 1, 2, 3, 4, 5]:
                explanations.append(f"üåô Very unusual time: {hour}:00 (typical hours: {active_hours[:3]})")
            else:
                explanations.append(f"‚è∞ Uncommon time: {hour}:00 (typical hours: {active_hours[:3]})")
        
        category = transaction['merchant_category']
        common_categories = list(profile['common_categories'].keys())
        
        if category not in common_categories[:3]:
            if category in ['electronics', 'jewelry', 'travel']:
                explanations.append(f"üéØ High-risk category: '{category}' (usual: {common_categories[:2]})")
            else:
                explanations.append(f"üè™ New category: '{category}' (usual: {common_categories[:2]})")
        
        if transaction['day_of_week'] in [5, 6]:
            if profile['weekend_ratio'] < 0.2:
                explanations.append("üìÖ Weekend transaction unusual for this user")
        
        explanations.append(f"ü§ñ ML confidence: {ml_score:.3f}, Rules: {rule_score:.3f}")
        
        return explanations if explanations else ["‚úÖ Transaction appears normal for this user"]

# Initialize global components
ml_engine = FraudGuardML()
persistence = ModelPersistence()
monitor = FraudGuardMonitor()

# Visual Dashboard Endpoint
@app.get("/dashboard")
def serve_visual_dashboard():
    """Serve the visual monitoring dashboard"""
    dashboard_path = os.path.join(os.path.dirname(__file__), "dashboard.html")
    if os.path.exists(dashboard_path):
        return FileResponse(dashboard_path)
    else:
        raise HTTPException(status_code=404, detail="Dashboard file not found. Please create dashboard.html in the project directory.")

# API Endpoints
@app.get("/")
def root():
    return {
        "message": "üõ°Ô∏è FraudGuard ML Service is online!",
        "version": "2.3.0",
        "status": "Ready for intelligent fraud detection with visual dashboard",
        "trained_users": len(ml_engine.profiles),
        "total_models": len(ml_engine.models),
        "features": [
            "Visual Dashboard",
            "Enhanced Error Handling",
            "Ensemble ML Models", 
            "Real-time Monitoring",
            "SHAP Explainable AI",
            "Advanced Pattern Recognition",
            "Model Persistence",
            "Automated Alerting"
        ],
        "endpoints": {
            "dashboard": "/dashboard",
            "api_docs": "/docs",
            "monitoring": "/monitoring/dashboard",
            "health": "/health"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.post("/train-user")
def train_user_model(data: TrainingData):
    """Train comprehensive behavioral model with detailed error logging"""
    try:
        logger.info(f"üß† Starting training for user: {data.user_id}")
        
        if len(data.transactions) < 15:
            logger.error(f"‚ùå Not enough transactions: {len(data.transactions)} < 15")
            raise HTTPException(
                status_code=400,
                detail="Need at least 15 transactions to train reliable behavioral model"
            )
        
        logger.info(f"‚úÖ Transaction count OK: {len(data.transactions)}")
        
        start_time = datetime.now()
        
        logger.info("üì¶ Converting transactions to dict format...")
        try:
            transactions = [t.model_dump() for t in data.transactions]
            logger.info(f"‚úÖ Successfully converted {len(transactions)} transactions")
        except Exception as e:
            logger.error(f"‚ùå Error converting transactions: {e}")
            raise
        
        logger.info("üèóÔ∏è Creating comprehensive profile...")
        try:
            profile = ml_engine.create_comprehensive_profile(data.user_id, transactions)
            logger.info(f"‚úÖ Profile created successfully")
        except Exception as e:
            logger.error(f"‚ùå Error creating profile: {e}")
            raise
        
        training_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"‚è±Ô∏è Training completed in {training_time:.2f}s")
        
        logger.info("üíæ Attempting to save model...")
        try:
            persistence.save_model(
                data.user_id,
                profile,
                ml_engine.models[data.user_id],
                ml_engine.scalers[data.user_id]
            )
            model_saved = True
            logger.info("‚úÖ Model saved successfully")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to auto-save model: {e}")
            model_saved = False
        
        logger.info(f"üéØ Successfully trained model for {data.user_id} in {training_time:.2f}s")
        
        result = {
            "status": "success",
            "message": f"Successfully trained ensemble behavioral model for {data.user_id}",
            "profile": profile,
            "model_trained": True,
            "ensemble_trained": data.user_id in ml_engine.ensemble_trained,
            "model_saved": model_saved,
            "shap_enabled": data.user_id in ml_engine.shap_explainer.explainers,
            "training_time_seconds": training_time,
            "model_metadata": {
                "isolation_forest": "200 estimators, 10% contamination",
                "ensemble_models": profile.get('ensemble_models', []),
                "features_used": ml_engine.feature_columns,
                "shap_explainer": "TreeExplainer"
            }
        }
        
        logger.info("üì§ Returning training result...")
        return jsonable_encoder(result)
        
    except HTTPException:
        logger.error("‚ùå HTTPException raised - re-raising")
        raise
    except Exception as e:
        logger.error(f"‚ùå CRITICAL ERROR in train_user_model: {e}")
        logger.error(f"üìç Full traceback: {traceback.format_exc()}")
        monitor.record_error("training_error", str(e))
        raise HTTPException(status_code=500, detail=f"Training failed: {str(e)}")
    
@app.get("/monitoring/cycles")
def get_fraud_cycles():
    """Get fraud cycle detection data for network visualization"""
    
    # Generate sample network data representing transaction relationships
    # In a real implementation, this would analyze actual transaction data
    
    nodes = [
        {"id": "user_001", "label": "Normal User 1", "color": "#00d2ff", "size": 20, "group": "normal", "risk_score": 0.1},
        {"id": "user_002", "label": "Normal User 2", "color": "#00d2ff", "size": 18, "group": "normal", "risk_score": 0.15},
        {"id": "user_003", "label": "Suspicious User", "color": "#fdcb6e", "size": 25, "group": "suspicious", "risk_score": 0.6},
        {"id": "user_004", "label": "High Risk User", "color": "#e17055", "size": 30, "group": "high_risk", "risk_score": 0.8},
        {"id": "user_005", "label": "Fraud Confirmed", "color": "#fd79a8", "size": 35, "group": "fraud", "risk_score": 0.95},
        {"id": "user_006", "label": "Business Account", "color": "#00d2ff", "size": 22, "group": "normal", "risk_score": 0.2},
        {"id": "merchant_001", "label": "Electronics Store", "color": "#a29bfe", "size": 40, "group": "merchant", "risk_score": 0.3},
        {"id": "merchant_002", "label": "Jewelry Store", "color": "#a29bfe", "size": 35, "group": "merchant", "risk_score": 0.7},
    ]
    
    edges = [
        {"from": "user_001", "to": "user_002", "color": {"color": "#3a7bd5"}, "width": 2, "label": "$150", "amount": 150, "suspicious": False},
        {"from": "user_002", "to": "user_003", "color": {"color": "#fdcb6e"}, "width": 3, "label": "$500", "amount": 500, "suspicious": True},
        {"from": "user_003", "to": "user_004", "color": {"color": "#e17055"}, "width": 4, "label": "$2,500", "amount": 2500, "suspicious": True},
        {"from": "user_004", "to": "user_005", "color": {"color": "#fd79a8"}, "width": 5, "label": "$5,000", "amount": 5000, "suspicious": True},
        {"from": "user_005", "to": "user_001", "color": {"color": "#fd79a8"}, "width": 4, "label": "$3,200", "amount": 3200, "suspicious": True, "dashes": True},  # CYCLE DETECTED
        {"from": "user_006", "to": "user_003", "color": {"color": "#3a7bd5"}, "width": 2, "label": "$300", "amount": 300, "suspicious": False},
        {"from": "user_003", "to": "merchant_001", "color": {"color": "#fdcb6e"}, "width": 6, "label": "$8,000", "amount": 8000, "suspicious": True},
        {"from": "user_004", "to": "merchant_002", "color": {"color": "#e17055"}, "width": 7, "label": "$12,000", "amount": 12000, "suspicious": True},
        {"from": "user_005", "to": "merchant_001", "color": {"color": "#fd79a8"}, "width": 8, "label": "$15,000", "amount": 15000, "suspicious": True},
    ]
    
    # Detect cycles (simple implementation)
    cycles_detected = [
        {
            "cycle_id": "cycle_001",
            "participants": ["user_001", "user_002", "user_003", "user_004", "user_005"],
            "total_amount": 11350,
            "risk_level": "HIGH",
            "confidence": 0.87
        }
    ]
    
    # Network statistics
    network_stats = {
        "total_nodes": len(nodes),
        "total_edges": len(edges),
        "suspicious_edges": len([e for e in edges if e.get("suspicious", False)]),
        "cycles_detected": len(cycles_detected),
        "max_risk_score": max([n["risk_score"] for n in nodes]),
        "avg_transaction_amount": sum([e["amount"] for e in edges]) / len(edges)
    }
    
    result = {
        "network_data": {
            "nodes": nodes,
            "edges": edges
        },
        "cycles": cycles_detected,
        "statistics": network_stats,
        "last_updated": datetime.now().isoformat(),
        "analysis_summary": {
            "fraud_rings_detected": 1,
            "suspicious_merchants": 1,
            "high_risk_users": 2,
            "total_suspicious_amount": 31200
        }
    }
    
    return jsonable_encoder(result)

@app.post("/detect-fraud")
def detect_fraud(transaction: Transaction):
    """FIXED: Advanced real-time fraud detection with numpy type conversion"""
    try:
        start_detection_time = datetime.now()
        
        result = ml_engine.detect_advanced_fraud(transaction.user_id, transaction.model_dump())
        
        total_processing_time = (datetime.now() - start_detection_time).total_seconds() * 1000
        
        if result['is_suspicious']:
            logger.warning(
                f"üö® FRAUD DETECTED: User {transaction.user_id}, "
                f"Amount: ${transaction.amount}, Risk: {result['risk_level']}"
            )
        
        # CRITICAL FIX: Convert any remaining numpy types
        result_clean = convert_numpy_types(result)
        json_compatible_result = jsonable_encoder(result_clean)
        
        return JSONResponse(content=json_compatible_result)
        
    except Exception as e:
        monitor.record_error("detection_error", str(e))
        logger.error(f"‚ùå Fraud detection failed: {str(e)}")
        logger.error(f"üìç Full traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"Detection failed: {str(e)}")

# Monitoring Endpoints
@app.get("/monitoring/metrics")
def get_monitoring_metrics():
    """Get current system metrics"""
    return jsonable_encoder(monitor.get_current_metrics())

@app.get("/monitoring/health")
def get_system_health():
    """Get system health status"""
    metrics = monitor.get_current_metrics()
    
    health_score = 100
    if metrics['fraud_rate'] > 0.1:
        health_score -= 20
    if metrics['avg_response_time_ms'] > 150:
        health_score -= 15
    if metrics['error_rate'] > 0.02:
        health_score -= 25
    health_score -= len(metrics['active_alerts']) * 10
    
    health_score = max(0, min(100, health_score))
    
    if health_score >= 90:
        health_status = "EXCELLENT"
    elif health_score >= 70:
        health_status = "GOOD"
    elif health_score >= 50:
        health_status = "FAIR"
    else:
        health_status = "POOR"
    
    result = {
        "system_health": health_status,
        "health_score": health_score,
        "active_alerts": metrics['active_alerts'],
        "key_metrics": {
            "total_requests": metrics['total_requests'],
            "fraud_rate": f"{metrics['fraud_rate']:.1%}",
            "avg_response_time": f"{metrics['avg_response_time_ms']:.1f}ms",
            "error_rate": f"{metrics['error_rate']:.1%}"
        },
        "timestamp": datetime.now().isoformat()
    }
    
    return jsonable_encoder(result)

@app.get("/monitoring/dashboard")
def get_monitoring_dashboard():
    """Get comprehensive monitoring dashboard data"""
    metrics = monitor.get_current_metrics()
    
    hourly_data = []
    for hour in range(24):
        stats = monitor.metrics['hourly_stats'][hour]
        if stats['requests'] > 0:
            hourly_fraud_rate = stats['fraud'] / stats['requests']
        else:
            hourly_fraud_rate = 0
        
        hourly_data.append({
            'hour': hour,
            'requests': stats['requests'],
            'fraud_count': stats['fraud'],
            'fraud_rate': hourly_fraud_rate
        })
    
    result = {
        "dashboard_title": "üõ°Ô∏è FraudGuard ML Monitoring Dashboard",
        "last_updated": datetime.now().isoformat(),
        "system_overview": metrics,
        "performance_charts": {
            "hourly_activity": hourly_data
        },
        "recent_incidents": monitor.metrics['high_risk_transactions'][-10:],
        "ensemble_info": {
            "users_with_ensemble": len([u for u in ml_engine.ensemble_trained.keys() if ml_engine.ensemble_trained[u]]),
            "total_users": len(ml_engine.profiles),
            "ensemble_coverage": f"{len([u for u in ml_engine.ensemble_trained.keys() if ml_engine.ensemble_trained[u]])}/{len(ml_engine.profiles)}"
        }
    }
    
    return jsonable_encoder(result)

@app.get("/health")
def health_check():
    """Comprehensive system health check"""
    result = {
        "status": "healthy",
        "service": "FraudGuard ML Service",
        "version": "2.3.0",
        "uptime": "Running",
        "metrics": {
            "trained_users": len(ml_engine.profiles),
            "loaded_models": len(ml_engine.models),
            "ensemble_models": len([u for u in ml_engine.ensemble_trained.keys() if ml_engine.ensemble_trained[u]]),
            "saved_models": len(persistence.list_models()),
            "shap_explainers": len(ml_engine.shap_explainer.explainers),
            "total_requests": monitor.metrics['total_requests'],
            "fraud_detected": monitor.metrics['fraud_detected']
        },
        "capabilities": [
            "Visual Dashboard with Real-time Charts",
            "Enhanced Error Handling & Debugging",
            "Fixed Ensemble ML Models",
            "Real-time Monitoring", 
            "SHAP Explainable AI",
            "Automated Alerting",
            "Pattern Recognition",
            "Model Persistence"
        ],
        "access_points": {
            "visual_dashboard": "/dashboard",
            "api_documentation": "/docs",
            "monitoring_api": "/monitoring/dashboard",
            "health_check": "/health"
        },
        "timestamp": datetime.now().isoformat()
    }
    
    return jsonable_encoder(result)

if __name__ == "__main__":
    import uvicorn
    logger.info("üöÄ Starting FraudGuard ML Service with Visual Dashboard...")
    logger.info("üìä Dashboard available at: http://localhost:8000/dashboard")
    logger.info("üîß API Documentation at: http://localhost:8000/docs")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
</file>

<file path="ml-service/mlservice_test.py">
import requests
import json

base_url = 'http://127.0.0.1:8000'

# Test Health Endpoint
response = requests.get(base_url + '/')
print(f'Health Endpoint responded with status: {response.status_code}')
print(response.json())

# Test Learn Endpoint
user_id = 'TESTUSER001'
transactions = [
    {"user_id": user_id, "amount": 20 + i, "merchant_category": "grocery", "hour": 10, "day_of_week": 2} for i in range(20)
]

response = requests.post(f'{base_url}/learn-user?user_id={user_id}', json=transactions)
print(f'Learn-user Endpoint responded with status: {response.status_code}')
print(response.json())

# Test Detect Endpoint Normal Transaction
normal_txn = {"user_id": user_id, "amount": 22, "merchant_category": "grocery", "hour": 10, "day_of_week": 2}
response = requests.post(f'{base_url}/detect-fraud', json=normal_txn)
print(f'Detect-fraud (normal) responded with status: {response.status_code}')
print(response.json())

# Test Detect Endpoint Suspicious Transaction
suspicious_txn = {"user_id": user_id, "amount": 1000, "merchant_category": "electronics", "hour": 3, "day_of_week": 6}
response = requests.post(f'{base_url}/detect-fraud', json=suspicious_txn)
print(f'Detect-fraud (suspicious) responded with status: {response.status_code}')
print(response.json())
</file>

<file path="ml-service/quick_test.py">
# Create this file in ml-service directory
import requests
import random

def generate_sample_transactions(user_id, count=20):
    """Generate sample transactions for testing"""
    transactions = []
    
    for i in range(count):
        transaction = {
            "user_id": user_id,
            "amount": round(random.uniform(20, 200), 2),
            "merchant_category": random.choice(['grocery', 'gas', 'restaurant', 'pharmacy']),
            "hour": random.randint(8, 20),
            "day_of_week": random.randint(0, 4),
            "location": "normal_area"
        }
        transactions.append(transaction)
    
    return transactions

def test_ml_service():
    """Test the ML service with sample data"""
    base_url = "http://localhost:8000"
    
    # 1. Check service health
    response = requests.get(f"{base_url}/")
    print("Service Status:", response.json()['message'])
    
    # 2. Train a user model
    user_id = "USER_TEST_001"
    transactions = generate_sample_transactions(user_id, 25)
    
    training_data = {
        "user_id": user_id,
        "transactions": transactions
    }
    
    response = requests.post(f"{base_url}/train-user", json=training_data)
    print("Training Result:", response.json()['message'])
    
    # 3. Test fraud detection - Normal transaction
    normal_txn = {
        "user_id": user_id,
        "amount": 75.0,
        "merchant_category": "grocery",
        "hour": 18,
        "day_of_week": 2
    }
    
    response = requests.post(f"{base_url}/detect-fraud", json=normal_txn)
    result = response.json()
    print(f"Normal Transaction: {result['risk_level']} (score: {result['anomaly_score']:.3f})")
    
    # 4. Test fraud detection - Suspicious transaction
    suspicious_txn = {
        "user_id": user_id,
        "amount": 2500.0,
        "merchant_category": "electronics",
        "hour": 3,
        "day_of_week": 6
    }
    
    response = requests.post(f"{base_url}/detect-fraud", json=suspicious_txn)
    result = response.json()
    print(f"Suspicious Transaction: {result['risk_level']} (score: {result['anomaly_score']:.3f})")
    print(f"Explanation: {result['explanation'][0][:60]}...")

if __name__ == "__main__":
    test_ml_service()
</file>

<file path="ml-service/requirements.txt">
fastapi==0.104.1
uvicorn==0.24.0
pandas==2.1.3
numpy==1.26.4
scikit-learn==1.3.2
pydantic==2.5.0
requests==2.31.0    
faker==19.12.0
joblib==1.3.2
shap>=0.42.1
</file>

<file path="ml-service/test_all_features.py">
import requests
import time
import random
import json

BASE_URL = "http://localhost:8000"

def test_all_features():
    """Comprehensive test of all FraudGuard features"""
    
    print("üõ°Ô∏è FRAUDGUARD ML COMPREHENSIVE TESTING")
    print("=" * 50)
    
    # 1. Test service health
    print("\n1Ô∏è‚É£ Testing Service Health...")
    response = requests.get(f"{BASE_URL}/")
    print(f"   Status: {response.status_code}")
    print(f"   Version: {response.json()['version']}")
    
    # 2. Train multiple user types
    print("\n2Ô∏è‚É£ Training Different User Profiles...")
    
    training_datasets = [
        {
            "user_id": "NORMAL_USER_001",
            "transactions": [
                {"user_id": "NORMAL_USER_001", "amount": 45.50, "merchant_category": "grocery", "hour": 18, "day_of_week": 1},
                {"user_id": "NORMAL_USER_001", "amount": 67.80, "merchant_category": "gas", "hour": 8, "day_of_week": 2},
                {"user_id": "NORMAL_USER_001", "amount": 89.20, "merchant_category": "restaurant", "hour": 19, "day_of_week": 3},
                {"user_id": "NORMAL_USER_001", "amount": 34.75, "merchant_category": "grocery", "hour": 17, "day_of_week": 4},
                {"user_id": "NORMAL_USER_001", "amount": 56.40, "merchant_category": "pharmacy", "hour": 16, "day_of_week": 5},
                {"user_id": "NORMAL_USER_001", "amount": 78.90, "merchant_category": "grocery", "hour": 18, "day_of_week": 1},
                {"user_id": "NORMAL_USER_001", "amount": 123.45, "merchant_category": "retail", "hour": 15, "day_of_week": 6},
                {"user_id": "NORMAL_USER_001", "amount": 41.20, "merchant_category": "gas", "hour": 9, "day_of_week": 1},
                {"user_id": "NORMAL_USER_001", "amount": 95.30, "merchant_category": "restaurant", "hour": 20, "day_of_week": 5},
                {"user_id": "NORMAL_USER_001", "amount": 52.15, "merchant_category": "grocery", "hour": 17, "day_of_week": 2},
                {"user_id": "NORMAL_USER_001", "amount": 69.85, "merchant_category": "pharmacy", "hour": 11, "day_of_week": 3},
                {"user_id": "NORMAL_USER_001", "amount": 144.60, "merchant_category": "retail", "hour": 14, "day_of_week": 4},
                {"user_id": "NORMAL_USER_001", "amount": 38.90, "merchant_category": "gas", "hour": 8, "day_of_week": 5},
                {"user_id": "NORMAL_USER_001", "amount": 87.25, "merchant_category": "restaurant", "hour": 19, "day_of_week": 6},
                {"user_id": "NORMAL_USER_001", "amount": 43.70, "merchant_category": "grocery", "hour": 18, "day_of_week": 0}
            ]
        },
        {
            "user_id": "BUSINESS_USER_001",
            "transactions": [
                {"user_id": "BUSINESS_USER_001", "amount": 450.00, "merchant_category": "office_supplies", "hour": 10, "day_of_week": 1},
                {"user_id": "BUSINESS_USER_001", "amount": 780.50, "merchant_category": "restaurant", "hour": 12, "day_of_week": 2},
                {"user_id": "BUSINESS_USER_001", "amount": 1250.75, "merchant_category": "travel", "hour": 14, "day_of_week": 3},
                {"user_id": "BUSINESS_USER_001", "amount": 320.00, "merchant_category": "gas", "hour": 9, "day_of_week": 4},
                {"user_id": "BUSINESS_USER_001", "amount": 890.25, "merchant_category": "electronics", "hour": 11, "day_of_week": 5},
                {"user_id": "BUSINESS_USER_001", "amount": 567.80, "merchant_category": "office_supplies", "hour": 10, "day_of_week": 1},
                {"user_id": "BUSINESS_USER_001", "amount": 1100.00, "merchant_category": "hotel", "hour": 16, "day_of_week": 2},
                {"user_id": "BUSINESS_USER_001", "amount": 234.50, "merchant_category": "restaurant", "hour": 13, "day_of_week": 3},
                {"user_id": "BUSINESS_USER_001", "amount": 675.30, "merchant_category": "retail", "hour": 15, "day_of_week": 4},
                {"user_id": "BUSINESS_USER_001", "amount": 445.90, "merchant_category": "gas", "hour": 8, "day_of_week": 5},
                {"user_id": "BUSINESS_USER_001", "amount": 1350.00, "merchant_category": "travel", "hour": 14, "day_of_week": 1},
                {"user_id": "BUSINESS_USER_001", "amount": 289.75, "merchant_category": "restaurant", "hour": 12, "day_of_week": 2},
                {"user_id": "BUSINESS_USER_001", "amount": 756.40, "merchant_category": "electronics", "hour": 11, "day_of_week": 3},
                {"user_id": "BUSINESS_USER_001", "amount": 398.20, "merchant_category": "office_supplies", "hour": 10, "day_of_week": 4},
                {"user_id": "BUSINESS_USER_001", "amount": 823.15, "merchant_category": "hotel", "hour": 16, "day_of_week": 5}
            ]
        }
    ]
    
    for dataset in training_datasets:
        response = requests.post(f"{BASE_URL}/train-user", json=dataset)
        if response.status_code == 200:
            print(f"   ‚úÖ Trained {dataset['user_id']}")
        else:
            print(f"   ‚ùå Failed to train {dataset['user_id']}: {response.text}")
    
    # 3. Test different fraud scenarios
    print("\n3Ô∏è‚É£ Testing Fraud Detection Scenarios...")
    
    test_cases = [
        {"name": "Normal Transaction", "data": {"user_id": "NORMAL_USER_001", "amount": 62.40, "merchant_category": "grocery", "hour": 18, "day_of_week": 2}},
        {"name": "Suspicious Amount", "data": {"user_id": "NORMAL_USER_001", "amount": 2800.00, "merchant_category": "grocery", "hour": 18, "day_of_week": 2}},
        {"name": "Suspicious Time", "data": {"user_id": "NORMAL_USER_001", "amount": 75.00, "merchant_category": "grocery", "hour": 3, "day_of_week": 2}},
        {"name": "Suspicious Category", "data": {"user_id": "NORMAL_USER_001", "amount": 85.00, "merchant_category": "gambling", "hour": 18, "day_of_week": 2}},
        {"name": "Multiple Red Flags", "data": {"user_id": "NORMAL_USER_001", "amount": 3500.00, "merchant_category": "jewelry", "hour": 2, "day_of_week": 6}},
        {"name": "Critical Risk", "data": {"user_id": "BUSINESS_USER_001", "amount": 15000.00, "merchant_category": "cash_advance", "hour": 4, "day_of_week": 0}}
    ]
    
    for test_case in test_cases:
        response = requests.post(f"{BASE_URL}/detect-fraud", json=test_case["data"])
        if response.status_code == 200:
            result = response.json()
            print(f"   {test_case['name']}: {result['risk_level']} ({result['anomaly_score']:.3f})")
        else:
            print(f"   ‚ùå {test_case['name']}: Failed")
    
    # 4. Test monitoring endpoints
    print("\n4Ô∏è‚É£ Testing Monitoring & Analytics...")
    
    endpoints = ["/monitoring/metrics", "/monitoring/health", "/monitoring/dashboard", "/health"]
    for endpoint in endpoints:
        response = requests.get(f"{BASE_URL}{endpoint}")
        print(f"   {endpoint}: {'‚úÖ' if response.status_code == 200 else '‚ùå'}")
    
    # 5. Load testing
    print("\n5Ô∏è‚É£ Load Testing (50 transactions)...")
    
    users = ["NORMAL_USER_001", "BUSINESS_USER_001"]
    fraud_count = 0
    
    for i in range(50):
        user = random.choice(users)
        
        if i % 10 == 0:  # 10% fraudulent
            transaction = {
                "user_id": user,
                "amount": random.uniform(3000, 8000),
                "merchant_category": random.choice(["electronics", "jewelry", "gambling"]),
                "hour": random.choice([1, 2, 3, 4]),
                "day_of_week": random.choice([5, 6])
            }
        else:  # 90% normal
            if user == "NORMAL_USER_001":
                transaction = {
                    "user_id": user,
                    "amount": random.uniform(30, 150),
                    "merchant_category": random.choice(["grocery", "gas", "restaurant"]),
                    "hour": random.randint(8, 20),
                    "day_of_week": random.randint(0, 4)
                }
            else:  # BUSINESS_USER_001
                transaction = {
                    "user_id": user,
                    "amount": random.uniform(200, 1200),
                    "merchant_category": random.choice(["restaurant", "travel", "office_supplies"]),
                    "hour": random.randint(9, 17),
                    "day_of_week": random.randint(0, 4)
                }
        
        response = requests.post(f"{BASE_URL}/detect-fraud", json=transaction)
        if response.status_code == 200:
            result = response.json()
            if result["is_suspicious"]:
                fraud_count += 1
            print(f"   Transaction {i+1}: {result['risk_level']} ({'FRAUD' if result['is_suspicious'] else 'SAFE'})")
        
        time.sleep(0.1)  # Small delay
    
    print(f"\n   üìä Load Test Results: {fraud_count}/50 flagged as fraud ({fraud_count/50*100:.1f}%)")
    
    # 6. Final metrics check
    print("\n6Ô∏è‚É£ Final System Metrics...")
    response = requests.get(f"{BASE_URL}/monitoring/dashboard")
    if response.status_code == 200:
        dashboard = response.json()
        overview = dashboard["system_overview"]
        print(f"   Total Requests: {overview['total_requests']}")
        print(f"   Fraud Rate: {overview['fraud_rate']:.1%}")
        print(f"   Avg Response Time: {overview['avg_response_time_ms']:.1f}ms")
        print(f"   Active Alerts: {len(overview['active_alerts'])}")
    
    print("\nüéâ COMPREHENSIVE TESTING COMPLETED!")
    print("=" * 50)

if __name__ == "__main__":
    test_all_features()
</file>

<file path="ml-service/test_fraudguard.py">
import requests

BASE_URL = "http://localhost:8000"

# Sample data to train
train_data = {
    "user_id": "TEST_USER",
    "transactions": [
        {"user_id": "TEST_USER", "amount": 50, "merchant_category": "grocery", "hour": 18, "day_of_week": 1},
        {"user_id": "TEST_USER", "amount": 75, "merchant_category": "gas", "hour": 8, "day_of_week": 2},
        {"user_id": "TEST_USER", "amount": 120, "merchant_category": "restaurant", "hour": 19, "day_of_week": 3},
        {"user_id": "TEST_USER", "amount": 45, "merchant_category": "grocery", "hour": 17, "day_of_week": 4},
        {"user_id": "TEST_USER", "amount": 89, "merchant_category": "pharmacy", "hour": 16, "day_of_week": 5},
        {"user_id": "TEST_USER", "amount": 67, "merchant_category": "grocery", "hour": 18, "day_of_week": 1},
        {"user_id": "TEST_USER", "amount": 134, "merchant_category": "retail", "hour": 15, "day_of_week": 6},
        {"user_id": "TEST_USER", "amount": 56, "merchant_category": "gas", "hour": 9, "day_of_week": 1},
        {"user_id": "TEST_USER", "amount": 98, "merchant_category": "restaurant", "hour": 20, "day_of_week": 5},
        {"user_id": "TEST_USER", "amount": 43, "merchant_category": "grocery", "hour": 17, "day_of_week": 2},
        {"user_id": "TEST_USER", "amount": 87, "merchant_category": "pharmacy", "hour": 11, "day_of_week": 3},
        {"user_id": "TEST_USER", "amount": 156, "merchant_category": "retail", "hour": 14, "day_of_week": 4},
        {"user_id": "TEST_USER", "amount": 62, "merchant_category": "gas", "hour": 8, "day_of_week": 5},
        {"user_id": "TEST_USER", "amount": 91, "merchant_category": "restaurant", "hour": 19, "day_of_week": 6},
        {"user_id": "TEST_USER", "amount": 38, "merchant_category": "grocery", "hour": 18, "day_of_week": 0}
    ]
}

# Sample test transactions
test_cases = [
    {
        "name": "Normal Transaction",
        "data": {"user_id": "TEST_USER", "amount": 75.50, "merchant_category": "grocery", "hour": 18, "day_of_week": 2}
    },
    {
        "name": "High Amount Suspicious",
        "data": {"user_id": "TEST_USER", "amount": 2300.00, "merchant_category": "electronics", "hour": 2, "day_of_week": 3}
    },
    {
        "name": "Late Night Suspicious",
        "data": {"user_id": "TEST_USER", "amount": 150.00, "merchant_category": "restaurant", "hour": 1, "day_of_week": 5}
    },
    {
        "name": "High Risk Category",
        "data": {"user_id": "TEST_USER", "amount": 500.00, "merchant_category": "jewelry", "hour": 14, "day_of_week": 2}
    }
]

def test_fraudguard():
    print("üõ°Ô∏è Testing FraudGuard ML Service")
    print("=" * 40)
    
    # 1. Test service health
    try:
        response = requests.get(f"{BASE_URL}/")
        print(f"‚úÖ Service Status: {response.json()['status']}")
    except Exception as e:
        print(f"‚ùå Service not accessible: {e}")
        return
    
    # 2. Train user
    print(f"\nüß† Training user: {train_data['user_id']}")
    try:
        response = requests.post(f"{BASE_URL}/train-user", json=train_data)
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Training successful!")
            print(f"   - Model trained: {result['model_trained']}")
            print(f"   - Ensemble enabled: {result['ensemble_trained']}")
            print(f"   - SHAP enabled: {result['shap_enabled']}")
        else:
            print(f"‚ùå Training failed: {response.text}")
            return
    except Exception as e:
        print(f"‚ùå Training error: {e}")
        return
    
    # 3. Test fraud detection
    print(f"\nüïµÔ∏è Testing Fraud Detection:")
    for test_case in test_cases:
        print(f"\n   Testing: {test_case['name']}")
        try:
            response = requests.post(f"{BASE_URL}/detect-fraud", json=test_case['data'])
            if response.status_code == 200:
                result = response.json()
                risk_emoji = "üö®" if result['is_suspicious'] else "‚úÖ"
                print(f"   {risk_emoji} Risk Level: {result['risk_level']}")
                print(f"   üìä Anomaly Score: {result['anomaly_score']:.3f}")
                print(f"   üí° Key Explanation: {result['explanation'][0] if result['explanation'] else 'N/A'}")
            else:
                print(f"   ‚ùå Detection failed: {response.text}")
        except Exception as e:
            print(f"   ‚ùå Detection error: {e}")
    
    # 4. Check monitoring
    print(f"\nüìä Checking Monitoring:")
    try:
        response = requests.get(f"{BASE_URL}/monitoring/metrics")
        if response.status_code == 200:
            metrics = response.json()
            print(f"   üìà Total Requests: {metrics['total_requests']}")
            print(f"   üö® Fraud Detected: {metrics['fraud_detected']}")
            print(f"   üìä Fraud Rate: {metrics['fraud_rate']:.1%}")
            print(f"   ‚ö° Avg Response Time: {metrics['avg_response_time_ms']:.1f}ms")
        else:
            print(f"   ‚ùå Monitoring failed: {response.text}")
    except Exception as e:
        print(f"   ‚ùå Monitoring error: {e}")
    
    print(f"\nüéâ Testing completed!")
    print("üìä Visit http://localhost:8000/dashboard for visual monitoring")

if __name__ == "__main__":
    test_fraudguard()
</file>

<file path=".gitignore">
venv/
__pycache__/
*.pyc
*.pyo
saved_models/
*.log
.DS_Store
.vscode/
.idea/
</file>

<file path="README.md">
# üõ°Ô∏è FraudGuard
AI-Powered Fraud Detection System

## Project Structure
- `backend/` - Spring Boot REST API
- `ml-service/` - Python ML models & fraud detection
- `frontend/` - React dashboard & visualization  
- `data/` - Sample datasets & database schemas
- `docker/` - Container configurations
- `docs/` - Documentation & architecture

## Quick Start
1. Clone repository
2. Set up each component in respective folders
3. Use Docker for local development

## Team Collaboration
- Create feature branches for development
- Submit pull requests for code review
- Follow standard Git workflow
</file>

<file path="requirements.txt">
fastapi==0.104.1
uvicorn[standard]==0.24.0
scikit-learn==1.3.2
pandas==2.1.4
numpy==1.24.4
shap==0.43.0
joblib==1.3.2
pydantic==2.5.0
python-multipart==0.0.6
requests==2.31.0
</file>

<file path="ml-service/dashboard.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üõ°Ô∏è FraudGuard ML Dashboard - Dark Theme</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.2.1/dist/chart.min.js"></script>
    <script src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%);
            min-height: 100vh;
            padding: 20px;
            color: #e0e6ed;
        }
        
        .container {
            max-width: 1600px;
            margin: 0 auto;
            background: linear-gradient(145deg, #1e1e2f, #2a2a3e);
            border-radius: 20px;
            box-shadow: 0 25px 70px rgba(0,0,0,0.4);
            overflow: hidden;
            border: 1px solid #3a3a5c;
        }
        
        .header {
            background: linear-gradient(45deg, #1a1a2e, #16213e, #0f3460);
            color: #ffffff;
            padding: 35px;
            text-align: center;
            position: relative;
            border-bottom: 2px solid #00d2ff;
        }
        
        .header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: radial-gradient(circle at 30% 20%, rgba(0, 210, 255, 0.1), transparent 50%);
            pointer-events: none;
        }
        
        .header h1 {
            font-size: 2.8em;
            margin-bottom: 12px;
            text-shadow: 0 4px 8px rgba(0, 210, 255, 0.3);
            background: linear-gradient(45deg, #00d2ff, #3a7bd5);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .header p {
            opacity: 0.9;
            font-size: 1.2em;
            color: #b8c6db;
        }
        
        .status-indicator {
            position: absolute;
            top: 25px;
            right: 25px;
            padding: 10px 18px;
            border-radius: 25px;
            font-size: 0.85em;
            font-weight: bold;
            animation: pulse 2s infinite;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        @keyframes pulse {
            0% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.8; transform: scale(1.05); }
            100% { opacity: 1; transform: scale(1); }
        }
        
        .status-online {
            background: linear-gradient(45deg, #00b894, #00cec9);
            color: white;
            box-shadow: 0 0 20px rgba(0, 184, 148, 0.4);
        }
        
        .status-offline {
            background: linear-gradient(45deg, #e17055, #fd79a8);
            color: white;
            box-shadow: 0 0 20px rgba(225, 112, 85, 0.4);
        }
        
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            padding: 35px;
            background: linear-gradient(145deg, #1e1e2f, #262638);
        }
        
        .metric-card {
            background: linear-gradient(145deg, #2a2a3e, #323248);
            padding: 30px;
            border-radius: 15px;
            box-shadow: 
                0 10px 30px rgba(0,0,0,0.3),
                inset 0 1px 0 rgba(255,255,255,0.1);
            text-align: center;
            transition: all 0.4s ease;
            border: 1px solid #3a3a5c;
            position: relative;
            overflow: hidden;
        }
        
        .metric-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #00d2ff, #3a7bd5);
            transform: scaleX(0);
            transition: transform 0.4s ease;
        }
        
        .metric-card:hover::before {
            transform: scaleX(1);
        }
        
        .metric-card:hover {
            transform: translateY(-10px);
            box-shadow: 
                0 20px 40px rgba(0,0,0,0.4),
                0 0 30px rgba(0, 210, 255, 0.2),
                inset 0 1px 0 rgba(255,255,255,0.15);
        }
        
        .metric-card.alert {
            border-color: #e17055;
            animation: alertGlow 2s infinite;
        }
        
        @keyframes alertGlow {
            0%, 100% { 
                border-color: #e17055;
                box-shadow: 0 10px 30px rgba(0,0,0,0.3), 0 0 15px rgba(225, 112, 85, 0.3);
            }
            50% { 
                border-color: #fd79a8;
                box-shadow: 0 10px 30px rgba(0,0,0,0.3), 0 0 25px rgba(253, 121, 168, 0.5);
            }
        }
        
        .metric-value {
            font-size: 2.8em;
            font-weight: bold;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #00d2ff, #3a7bd5);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .metric-label {
            color: #b8c6db;
            font-size: 0.95em;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            margin-bottom: 8px;
            font-weight: 500;
        }
        
        .metric-trend {
            font-size: 0.85em;
            margin-top: 8px;
            padding: 5px 10px;
            border-radius: 20px;
            background: rgba(255,255,255,0.05);
            backdrop-filter: blur(5px);
        }
        
        .trend-up { 
            color: #00b894; 
            background: rgba(0, 184, 148, 0.1);
        }
        .trend-down { 
            color: #e17055; 
            background: rgba(225, 112, 85, 0.1);
        }
        .trend-stable { 
            color: #fdcb6e; 
            background: rgba(253, 203, 110, 0.1);
        }
        
        .charts-section {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            padding: 35px;
            background: linear-gradient(145deg, #1e1e2f, #262638);
        }
        
        .chart-container {
            background: linear-gradient(145deg, #2a2a3e, #323248);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 
                0 10px 30px rgba(0,0,0,0.3),
                inset 0 1px 0 rgba(255,255,255,0.1);
            border: 1px solid #3a3a5c;
            position: relative;
        }
        
        .chart-title {
            font-size: 1.5em;
            margin-bottom: 20px;
            color: #e0e6ed;
            display: flex;
            align-items: center;
            gap: 12px;
            font-weight: 600;
        }
        
        .chart-subtitle {
            font-size: 0.9em;
            color: #b8c6db;
            margin-bottom: 20px;
            opacity: 0.8;
        }
        
        .graph-section {
            grid-column: 1 / -1;
            background: linear-gradient(145deg, #2a2a3e, #323248);
            border-radius: 15px;
            padding: 30px;
            box-shadow: 
                0 10px 30px rgba(0,0,0,0.3),
                inset 0 1px 0 rgba(255,255,255,0.1);
            border: 1px solid #3a3a5c;
            margin-top: 20px;
        }
        
        #fraudChart, #trendChart {
            max-height: 350px;
        }
        
        #networkGraph {
            width: 100%;
            height: 500px;
            border-radius: 12px;
            background: linear-gradient(145deg, #1e1e2f, #262638);
            border: 1px solid #3a3a5c;
        }
        
        .fraud-rate-high { color: #e17055; }
        .fraud-rate-medium { color: #fdcb6e; }
        .fraud-rate-low { color: #00b894; }
        
        .error-message {
            background: linear-gradient(45deg, rgba(225, 112, 85, 0.2), rgba(253, 121, 168, 0.2));
            color: #fd79a8;
            padding: 25px;
            margin: 25px;
            border-radius: 12px;
            text-align: center;
            display: none;
            border-left: 4px solid #e17055;
            backdrop-filter: blur(10px);
        }
        
        .last-updated {
            text-align: center;
            padding: 25px;
            color: #b8c6db;
            font-size: 0.95em;
            background: linear-gradient(145deg, #1e1e2f, #262638);
            border-top: 1px solid #3a3a5c;
        }
        
        .loading-spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,0.1);
            border-top: 3px solid #00d2ff;
            border-radius: 50%;
            animation: spin 1s linear infinite;
            margin-right: 10px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .system-health {
            display: flex;
            align-items: center;
            gap: 20px;
            padding: 25px;
            background: linear-gradient(45deg, rgba(0, 184, 148, 0.1), rgba(0, 206, 201, 0.1));
            margin: 25px;
            border-radius: 12px;
            border-left: 4px solid #00b894;
            backdrop-filter: blur(10px);
        }
        
        .health-indicator {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: white;
            font-size: 1.1em;
            box-shadow: 0 0 20px rgba(0,0,0,0.3);
        }
        
        .health-excellent { 
            background: linear-gradient(45deg, #00b894, #00cec9); 
            box-shadow: 0 0 25px rgba(0, 184, 148, 0.4);
        }
        .health-good { 
            background: linear-gradient(45deg, #fdcb6e, #e17055); 
            box-shadow: 0 0 25px rgba(253, 203, 110, 0.4);
        }
        .health-poor { 
            background: linear-gradient(45deg, #e17055, #fd79a8); 
            box-shadow: 0 0 25px rgba(225, 112, 85, 0.4);
        }
        
        .recent-alerts {
            background: linear-gradient(45deg, rgba(253, 203, 110, 0.1), rgba(225, 112, 85, 0.1));
            border-left: 4px solid #fdcb6e;
            padding: 20px;
            margin: 25px;
            border-radius: 12px;
            backdrop-filter: blur(10px);
        }
        
        .recent-alerts h3 {
            color: #fdcb6e;
            margin-bottom: 15px;
            font-size: 1.2em;
        }
        
        .alert-item {
            padding: 12px 0;
            border-bottom: 1px solid rgba(255,255,255,0.1);
            font-size: 0.9em;
            color: #e0e6ed;
        }
        
        .controls-panel {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        
        .control-button {
            padding: 8px 16px;
            background: linear-gradient(45deg, #00d2ff, #3a7bd5);
            color: white;
            border: none;
            border-radius: 20px;
            cursor: pointer;
            font-size: 0.85em;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 210, 255, 0.3);
        }
        
        .control-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 210, 255, 0.4);
        }
        
        .network-legend {
            display: flex;
            gap: 20px;
            margin-top: 15px;
            font-size: 0.85em;
            color: #b8c6db;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .legend-color {
            width: 12px;
            height: 12px;
            border-radius: 50%;
        }
        
        @media (max-width: 1200px) {
            .charts-section {
                grid-template-columns: 1fr;
            }
        }
        
        @media (max-width: 768px) {
            .metrics-grid {
                grid-template-columns: 1fr;
                padding: 20px;
            }
            
            .charts-section {
                padding: 20px;
            }
            
            .header h1 {
                font-size: 2.2em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="status-indicator" id="statusIndicator">‚óè OFFLINE</div>
            <h1>üõ°Ô∏è FraudGuard ML Dashboard</h1>
            <p>Advanced AI-Powered Fraud Detection with Cyclic Network Analysis</p>
        </div>
        
        <div class="error-message" id="errorMessage">
            <div class="loading-spinner"></div>
            Unable to connect to FraudGuard service. Please ensure the service is running on localhost:8000
        </div>
        
        <div class="system-health" id="systemHealth" style="display: none;">
            <div class="health-indicator" id="healthIndicator">95</div>
            <div>
                <h3>System Health: <span id="healthStatus">Excellent</span></h3>
                <p>All fraud detection systems operational. ML models performing optimally.</p>
            </div>
        </div>
        
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value" id="totalRequests">-</div>
                <div class="metric-label">Total Requests</div>
                <div class="metric-trend trend-up" id="requestsTrend">‚Üó +12% from last hour</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-value" id="fraudRate">-</div>
                <div class="metric-label">Fraud Rate</div>
                <div class="metric-trend" id="fraudTrend">Monitoring...</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-value" id="avgResponseTime">-</div>
                <div class="metric-label">Avg Response Time</div>
                <div class="metric-trend trend-stable" id="responseTrend">‚äô Stable</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-value" id="activeAlerts">-</div>
                <div class="metric-label">Active Alerts</div>
                <div class="metric-trend" id="alertsTrend">System monitoring...</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-value" id="trainedUsers">-</div>
                <div class="metric-label">Trained Users</div>
                <div class="metric-trend trend-up" id="usersTrend">Models ready</div>
            </div>
            
            <div class="metric-card">
                <div class="metric-value" id="ensembleCoverage">-</div>
                <div class="metric-label">ML Coverage</div>
                <div class="metric-trend" id="coverageTrend">AI models active</div>
            </div>
        </div>
        
        <div class="charts-section">
            <div class="chart-container">
                <h2 class="chart-title">üìä Transaction Activity</h2>
                <div class="chart-subtitle">Real-time hourly breakdown of transactions and fraud detection</div>
                <canvas id="fraudChart"></canvas>
            </div>
            
            <div class="chart-container">
                <h2 class="chart-title">üìà Fraud Rate Trend</h2>
                <div class="chart-subtitle">24-hour fraud rate trend analysis</div>
                <canvas id="trendChart"></canvas>
            </div>
            
            <div class="graph-section">
                <h2 class="chart-title">üîó Fraud Network Analysis</h2>
                <div class="chart-subtitle">Interactive graph showing transaction relationships and potential fraud cycles</div>
                
                <div class="controls-panel">
                    <button class="control-button" onclick="regenerateNetwork()">üîÑ Regenerate Network</button>
                    <button class="control-button" onclick="togglePhysics()">‚ö° Toggle Physics</button>
                    <button class="control-button" onclick="fitNetwork()">üéØ Fit View</button>
                    <button class="control-button" onclick="exportNetwork()">üíæ Export Graph</button>
                </div>
                
                <div id="networkGraph"></div>
                
                <div class="network-legend">
                    <div class="legend-item">
                        <div class="legend-color" style="background: #00d2ff;"></div>
                        <span>Normal User</span>
                    </div>
                    <div class="legend-item">
                        <div class="legend-color" style="background: #fdcb6e;"></div>
                        <span>Suspicious Activity</span>
                    </div>
                    <div class="legend-item">
                        <div class="legend-color" style="background: #e17055;"></div>
                        <span>High Risk</span>
                    </div>
                    <div class="legend-item">
                        <div class="legend-color" style="background: #fd79a8;"></div>
                        <span>Confirmed Fraud</span>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="recent-alerts" id="recentAlerts" style="display: none;">
            <h3>üö® Recent High-Risk Detections</h3>
            <div id="alertsList">No recent high-risk transactions detected.</div>
        </div>
        
        <div class="last-updated" id="lastUpdated">
            <div class="loading-spinner"></div>
            Initializing FraudGuard Dark Dashboard...
        </div>
    </div>

    <script>
        let fraudChart = null;
        let trendChart = null;
        let network = null;
        let isOnline = false;
        let previousData = null;
        let physicsEnabled = true;
        
        // Initialize all visualizations
        function initDashboard() {
            initCharts();
            initNetworkGraph();
            fetchDashboardData();
        }
        
        // Initialize Chart.js with dark theme
        function initCharts() {
            Chart.defaults.color = '#e0e6ed';
            Chart.defaults.borderColor = '#3a3a5c';
            Chart.defaults.backgroundColor = 'rgba(0, 210, 255, 0.1)';
            
            const fraudCtx = document.getElementById('fraudChart').getContext('2d');
            const trendCtx = document.getElementById('trendChart').getContext('2d');
            
            // Main fraud activity chart
            fraudChart = new Chart(fraudCtx, {
                type: 'bar',
                data: {
                    labels: [],
                    datasets: [{
                        label: 'Total Requests',
                        data: [],
                        backgroundColor: 'rgba(0, 210, 255, 0.8)',
                        borderColor: '#00d2ff',
                        borderWidth: 2,
                        borderRadius: 6,
                        borderSkipped: false,
                    }, {
                        label: 'Fraud Detected',
                        data: [],
                        backgroundColor: 'rgba(225, 112, 85, 0.8)',
                        borderColor: '#e17055',
                        borderWidth: 2,
                        borderRadius: 6,
                        borderSkipped: false,
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {
                        legend: {
                            labels: {
                                color: '#e0e6ed',
                                usePointStyle: true,
                                padding: 20
                            }
                        },
                        tooltip: {
                            backgroundColor: 'rgba(26, 26, 46, 0.95)',
                            titleColor: '#00d2ff',
                            bodyColor: '#e0e6ed',
                            borderColor: '#3a3a5c',
                            borderWidth: 1,
                            cornerRadius: 8
                        }
                    },
                    scales: {
                        y: {
                            beginAtZero: true,
                            ticks: {
                                color: '#b8c6db',
                                stepSize: 1
                            },
                            grid: {
                                color: 'rgba(255, 255, 255, 0.1)',
                                drawBorder: false
                            }
                        },
                        x: {
                            ticks: {
                                color: '#b8c6db'
                            },
                            grid: {
                                display: false
                            }
                        }
                    },
                    animation: {
                        duration: 1200,
                        easing: 'easeInOutQuart'
                    }
                }
            });
            
            // Trend line chart
            trendChart = new Chart(trendCtx, {
                type: 'line',
                data: {
                    labels: [],
                    datasets: [{
                        label: 'Fraud Rate %',
                        data: [],
                        borderColor: '#fd79a8',
                        backgroundColor: 'rgba(253, 121, 168, 0.1)',
                        borderWidth: 3,
                        fill: true,
                        tension: 0.4,
                        pointBackgroundColor: '#fd79a8',
                        pointBorderColor: '#2a2a3e',
                        pointBorderWidth: 3,
                        pointRadius: 6,
                        pointHoverRadius: 8
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    plugins: {
                        legend: {
                            display: false
                        },
                        tooltip: {
                            backgroundColor: 'rgba(26, 26, 46, 0.95)',
                            titleColor: '#fd79a8',
                            bodyColor: '#e0e6ed',
                            borderColor: '#3a3a5c',
                            borderWidth: 1,
                            cornerRadius: 8,
                            callbacks: {
                                label: function(context) {
                                    return `Fraud Rate: ${context.parsed.y.toFixed(2)}%`;
                                }
                            }
                        }
                    },
                    scales: {
                        y: {
                            beginAtZero: true,
                            max: 100,
                            ticks: {
                                color: '#b8c6db',
                                callback: function(value) {
                                    return value + '%';
                                }
                            },
                            grid: {
                                color: 'rgba(255, 255, 255, 0.1)',
                                drawBorder: false
                            }
                        },
                        x: {
                            ticks: {
                                color: '#b8c6db'
                            },
                            grid: {
                                display: false
                            }
                        }
                    },
                    animation: {
                        duration: 1200,
                        easing: 'easeInOutQuart'
                    }
                }
            });
        }
        
        // Initialize Network Graph with dark theme
        function initNetworkGraph() {
            const container = document.getElementById('networkGraph');
            
            // Generate sample fraud network data
            const nodes = new vis.DataSet([
                {id: 'user1', label: 'Normal User 1', color: '#00d2ff', size: 20, group: 'normal'},
                {id: 'user2', label: 'Normal User 2', color: '#00d2ff', size: 18, group: 'normal'},
                {id: 'user3', label: 'Suspicious User', color: '#fdcb6e', size: 25, group: 'suspicious'},
                {id: 'user4', label: 'High Risk User', color: '#e17055', size: 30, group: 'high_risk'},
                {id: 'user5', label: 'Fraud Confirmed', color: '#fd79a8', size: 35, group: 'fraud'},
                {id: 'user6', label: 'Normal User 3', color: '#00d2ff', size: 22, group: 'normal'},
                {id: 'user7', label: 'Suspicious User 2', color: '#fdcb6e', size: 28, group: 'suspicious'},
                {id: 'merchant1', label: 'Electronics Store', color: '#a29bfe', size: 40, group: 'merchant'},
                {id: 'merchant2', label: 'Jewelry Store', color: '#a29bfe', size: 35, group: 'merchant'},
            ]);
            
            const edges = new vis.DataSet([
                {from: 'user1', to: 'user2', color: {color: '#3a7bd5'}, width: 2, label: '$150'},
                {from: 'user2', to: 'user3', color: {color: '#fdcb6e'}, width: 3, label: '$500'},
                {from: 'user3', to: 'user4', color: {color: '#e17055'}, width: 4, label: '$2,500'},
                {from: 'user4', to: 'user5', color: {color: '#fd79a8'}, width: 5, label: '$5,000'},
                {from: 'user5', to: 'user1', color: {color: '#fd79a8'}, width: 4, label: '$3,200', dashes: true}, // Cycle detected!
                {from: 'user6', to: 'user7', color: {color: '#3a7bd5'}, width: 2, label: '$300'},
                {from: 'user3', to: 'merchant1', color: {color: '#fdcb6e'}, width: 6, label: '$8,000'},
                {from: 'user4', to: 'merchant2', color: {color: '#e17055'}, width: 7, label: '$12,000'},
                {from: 'user5', to: 'merchant1', color: {color: '#fd79a8'}, width: 8, label: '$15,000'},
            ]);
            
            const data = { nodes, edges };
            
            const options = {
                nodes: {
                    shape: 'dot',
                    font: {
                        color: '#e0e6ed',
                        size: 12,
                        face: 'Segoe UI'
                    },
                    borderWidth: 2,
                    borderColor: '#3a3a5c',
                    shadow: {
                        enabled: true,
                        color: 'rgba(0,0,0,0.3)',
                        size: 10,
                        x: 2,
                        y: 2
                    },
                    chosen: {
                        node: function(values, id, selected, hovering) {
                            values.color = '#00d2ff';
                            values.size = values.size * 1.2;
                        }
                    }
                },
                edges: {
                    arrows: {
                        to: {
                            enabled: true,
                            scaleFactor: 1.2
                        }
                    },
                    font: {
                        color: '#b8c6db',
                        size: 10,
                        strokeWidth: 2,
                        strokeColor: '#1e1e2f'
                    },
                    smooth: {
                        type: 'dynamic',
                        roundness: 0.5
                    },
                    shadow: {
                        enabled: true,
                        color: 'rgba(0,0,0,0.2)',
                        size: 5,
                        x: 1,
                        y: 1
                    }
                },
                physics: {
                    enabled: true,
                    solver: 'forceAtlas2Based',
                    forceAtlas2Based: {
                        gravitationalConstant: -50,
                        centralGravity: 0.01,
                        springLength: 100,
                        springConstant: 0.08,
                        damping: 0.4,
                        avoidOverlap: 0.5
                    },
                    maxVelocity: 30,
                    minVelocity: 0.75,
                    timestep: 0.35,
                    adaptiveTimestep: true,
                    stabilization: {
                        enabled: true,
                        iterations: 1000,
                        updateInterval: 25,
                        onlyDynamicEdges: false,
                        fit: true
                    }
                },
                interaction: {
                    hover: true,
                    hoverConnectedEdges: true,
                    selectConnectedEdges: false,
                    tooltipDelay: 200
                },
                layout: {
                    improvedLayout: true,
                    randomSeed: 42
                }
            };
            
            network = new vis.Network(container, data, options);
            
            // Add event listeners
            network.on('click', function(params) {
                if (params.nodes.length > 0) {
                    const nodeId = params.nodes[0];
                    console.log('Clicked node:', nodeId);
                    highlightNode(nodeId);
                }
            });
            
            network.on('hoverNode', function(params) {
                const nodeId = params.node;
                showNodeTooltip(nodeId, params.pointer.DOM);
            });
        }
        
        // Network control functions
        function regenerateNetwork() {
            // Add some randomness to the network
            const newNodes = network.body.data.nodes.get();
            newNodes.forEach(node => {
                if (Math.random() > 0.7) {
                    node.color = node.group === 'fraud' ? '#fd79a8' : 
                                node.group === 'high_risk' ? '#e17055' :
                                node.group === 'suspicious' ? '#fdcb6e' : '#00d2ff';
                }
            });
            network.setData({nodes: newNodes, edges: network.body.data.edges.get()});
        }
        
        function togglePhysics() {
            physicsEnabled = !physicsEnabled;
            network.setOptions({physics: {enabled: physicsEnabled}});
            console.log('Physics:', physicsEnabled ? 'Enabled' : 'Disabled');
        }
        
        function fitNetwork() {
            network.fit({
                animation: {
                    duration: 1000,
                    easingFunction: 'easeInOutQuad'
                }
            });
        }
        
        function exportNetwork() {
            // Simple export functionality
            const networkData = {
                nodes: network.body.data.nodes.get(),
                edges: network.body.data.edges.get()
            };
            console.log('Network data exported:', networkData);
            alert('Network data exported to console');
        }
        
        function highlightNode(nodeId) {
            const connectedNodes = network.getConnectedNodes(nodeId);
            const connectedEdges = network.getConnectedEdges(nodeId);
            
            console.log(`Node ${nodeId} is connected to:`, connectedNodes);
            console.log(`Connected edges:`, connectedEdges);
        }
        
        function showNodeTooltip(nodeId, position) {
            // This could show detailed information about the node
            console.log(`Hovering over node: ${nodeId}`);
        }
        
        // Enhanced data fetching and dashboard updates
        async function fetchDashboardData() {
            try {
                const response = await fetch('http://localhost:8000/monitoring/dashboard');
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                
                const data = await response.json();
                updateDashboard(data);
                setOnlineStatus(true);
                
            } catch (error) {
                console.error('Failed to fetch dashboard data:', error);
                setOnlineStatus(false);
            }
        }
        
        // Update dashboard with enhanced animations
        function updateDashboard(data) {
            const overview = data.system_overview;
            
            // Update metrics with smooth animations
            animateValue('totalRequests', parseInt(document.getElementById('totalRequests').textContent.replace(/,/g, '') || 0), overview.total_requests);
            
            const fraudRate = (overview.fraud_rate * 100).toFixed(1) + '%';
            const fraudRateElement = document.getElementById('fraudRate');
            fraudRateElement.textContent = fraudRate;
            
            // Enhanced fraud rate coloring
            const rate = overview.fraud_rate;
            fraudRateElement.className = 'metric-value ' + 
                (rate > 0.15 ? 'fraud-rate-high' : rate > 0.05 ? 'fraud-rate-medium' : 'fraud-rate-low');
            
            // Update other metrics
            document.getElementById('avgResponseTime').textContent = overview.avg_response_time_ms.toFixed(1) + ' ms';
            document.getElementById('activeAlerts').textContent = overview.active_alerts.length;
            
            // Alert styling
            const alertCard = document.getElementById('activeAlerts').closest('.metric-card');
            if (overview.active_alerts.length > 0) {
                alertCard.classList.add('alert');
            } else {
                alertCard.classList.remove('alert');
            }
            
            // Ensemble info
            if (data.ensemble_info) {
                document.getElementById('trainedUsers').textContent = data.ensemble_info.total_users;
                document.getElementById('ensembleCoverage').textContent = data.ensemble_info.ensemble_coverage;
            }
            
            // Update system health
            updateSystemHealth(overview);
            
            // Update charts
            updateCharts(data.performance_charts.hourly_activity);
            
            // Update recent alerts
            updateRecentAlerts(data.recent_incidents || []);
            
            // Update timestamp
            document.getElementById('lastUpdated').innerHTML = 
                `<span style="color: #00b894;">‚óè</span> Last updated: ${new Date().toLocaleTimeString()} - Dark Dashboard Active`;
            
            previousData = data;
        }
        
        // Animate number changes with enhanced effects
        function animateValue(elementId, start, end) {
            const element = document.getElementById(elementId);
            const duration = 1500;
            const startTimestamp = performance.now();
            
            function step(timestamp) {
                const progress = Math.min((timestamp - startTimestamp) / duration, 1);
                const current = Math.floor(progress * (end - start) + start);
                element.textContent = current.toLocaleString();
                
                if (progress < 1) {
                    requestAnimationFrame(step);
                } else {
                    // Add a subtle glow effect when animation completes
                    element.style.textShadow = '0 0 10px rgba(0, 210, 255, 0.5)';
                    setTimeout(() => {
                        element.style.textShadow = '';
                    }, 500);
                }
            }
            
            requestAnimationFrame(step);
        }
        
        // Update system health with enhanced styling
        function updateSystemHealth(overview) {
            const healthSection = document.getElementById('systemHealth');
            const healthIndicator = document.getElementById('healthIndicator');
            const healthStatus = document.getElementById('healthStatus');
            
            let healthScore = 100;
            if (overview.fraud_rate > 0.15) healthScore -= 30;
            if (overview.avg_response_time_ms > 100) healthScore -= 20;
            if (overview.active_alerts.length > 0) healthScore -= 25;
            
            healthScore = Math.max(0, healthScore);
            healthIndicator.textContent = healthScore;
            
            // Update health status and styling
            healthIndicator.className = 'health-indicator ';
            if (healthScore >= 90) {
                healthIndicator.className += 'health-excellent';
                healthStatus.textContent = 'Excellent';
            } else if (healthScore >= 70) {
                healthIndicator.className += 'health-good';
                healthStatus.textContent = 'Good';
            } else {
                healthIndicator.className += 'health-poor';
                healthStatus.textContent = 'Needs Attention';
            }
            
            healthSection.style.display = 'flex';
        }
        
        // Update charts with dark theme
        function updateCharts(hourlyData) {
            if (!fraudChart || !trendChart || !hourlyData) return;
            
            const hours = hourlyData.map(item => item.hour + ':00');
            const requests = hourlyData.map(item => item.requests);
            const frauds = hourlyData.map(item => item.fraud_count || 0);
            
            // Update main chart
            fraudChart.data.labels = hours;
            fraudChart.data.datasets[0].data = requests;
            fraudChart.data.datasets[1].data = frauds;
            fraudChart.update('active');
            
            // Update trend chart
            const trendData = hourlyData.map(item => {
                return item.requests > 0 ? (item.fraud_count / item.requests * 100) : 0;
            });
            
            trendChart.data.labels = hours;
            trendChart.data.datasets[0].data = trendData;
            trendChart.update('active');
        }
        
        // Update recent alerts with dark theme
        function updateRecentAlerts(incidents) {
            const alertsSection = document.getElementById('recentAlerts');
            const alertsList = document.getElementById('alertsList');
            
            if (incidents.length > 0) {
                alertsSection.style.display = 'block';
                alertsList.innerHTML = incidents.slice(0, 5).map(incident => 
                    `<div class="alert-item">
                        <strong style="color: #fd79a8;">${incident.user_id}</strong> - 
                        Risk: <span style="color: #e17055;">${incident.risk_level}</span> 
                        (Score: ${incident.anomaly_score.toFixed(3)}) - 
                        <span style="color: #b8c6db;">${new Date(incident.timestamp).toLocaleTimeString()}</span>
                    </div>`
                ).join('');
            } else {
                alertsSection.style.display = 'none';
            }
        }
        
        // Enhanced online/offline status
        function setOnlineStatus(online) {
            const statusElement = document.getElementById('statusIndicator');
            const errorElement = document.getElementById('errorMessage');
            
            if (online && !isOnline) {
                statusElement.textContent = '‚óè ONLINE';
                statusElement.className = 'status-indicator status-online';
                errorElement.style.display = 'none';
                isOnline = true;
            } else if (!online && isOnline) {
                statusElement.textContent = '‚óè OFFLINE';
                statusElement.className = 'status-indicator status-offline';
                errorElement.style.display = 'block';
                isOnline = false;
            }
        }
        
        // Initialize dashboard when page loads
        document.addEventListener('DOMContentLoaded', function() {
            initDashboard();
            
            // Auto-refresh every 5 seconds
            setInterval(fetchDashboardData, 5000);
        });
        
        // Handle page visibility changes
        document.addEventListener('visibilitychange', function() {
            if (!document.hidden) {
                fetchDashboardData();
            }
        });
        
        // Keyboard shortcuts
        document.addEventListener('keydown', function(e) {
            if (e.key === 'F5' || (e.ctrlKey && e.key === 'r')) {
                e.preventDefault();
                fetchDashboardData();
            }
            if (e.key === 'f' && e.ctrlKey) {
                e.preventDefault();
                fitNetwork();
            }
            if (e.key === 'p' && e.ctrlKey) {
                e.preventDefault();
                togglePhysics();
            }
        });
    </script>
</body>
</html>
</file>

<file path="ml-service/README.md">
# ML Service - Python ML Models
python3 -m venv venv
source venv/bin/activate     # Linux/macOS
# venv\Scripts\activate      # Windows

# 3. Install dependencies
pip install --upgrade pip
pip install -r requirements.txt
python app.py
</file>

</files>
